{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y73xWUkpU1AC"
      },
      "source": [
        "<br><br>\n",
        "\n",
        "## **Import necessary Python libraries and modules**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJ9kmfrO3M_w"
      },
      "source": [
        "First, we will import necessary Python libraries and modules. These include as `gdown`, for downloading large files from Google Drive (where we will get our UCSD Goodreads reviews), as well as scikit-learn (`sklearn`) and PyTorch (`torch`), for various machine learning tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "x9Si6kIWcULv"
      },
      "outputs": [],
      "source": [
        "\n",
        "# For data manipulation and analysis\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# For machine learning tools and evaluation\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
        "\n",
        "\n",
        "# For deep learning\n",
        "# https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
        "import torch\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4N0RIalt28yL"
      },
      "source": [
        "To use the HuggingFace [`transformers` Python library](https://huggingface.co/transformers/installation.html), we will install it with `pip`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNxmMnzoccfm",
        "outputId": "949cd49a-c8ea-4df6-8d2c-3b1c2d0e3a9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 49.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting tokenizers!=0.11.3,>=0.10.1\n",
            "  Downloading tokenizers-0.11.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 39.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 49.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.4 transformers-4.16.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f29CPpKi3__Q"
      },
      "source": [
        "Once `transformers` is installed, we will import modules for `DistilBert`, a *distilled* or smaller version of a BERT model that runs more quickly and uses less computing power. This makes it ideal for those just getting started with BERT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8ARMrKfmceAb"
      },
      "outputs": [],
      "source": [
        "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
        "from transformers import Trainer, TrainingArguments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q70KYS_NVSDL"
      },
      "source": [
        "<br><br>\n",
        "\n",
        "## **Set parameters and file paths**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "piWsW9ZeaP_D"
      },
      "outputs": [],
      "source": [
        "# This is the name of the BERT model that we want to use. \n",
        "# We're using DistilBERT to save space (it's a distilled version of the full BERT model), \n",
        "# and we're going to use the cased (vs uncased) version.\n",
        "model_name = 'distilbert-base-multilingual-cased'  \n",
        "\n",
        "# This is the name of the program management system for NVIDIA GPUs. We're going to send our code here.\n",
        "device_name = 'cuda'       \n",
        "\n",
        "# This is the maximum number of tokens in any document sent to BERT.\n",
        "max_length = 512                                                        \n",
        "\n",
        "# This is the name of the directory where we'll save our model. You can name it whatever you want.\n",
        "#cached_model_directory_name = 'ABSA_FineTuning_BERT'  \n",
        "cached_model_directory_name = 'Polarity_2c'  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVgnQsf9VnYE"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7P5FuT-DWnMm",
        "outputId": "ebf433a1-cec6-446c-8b8e-afcb55e33984"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ]
        }
      ],
      "source": [
        "#stiamo utlizzando la GPU?\n",
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "X83oPpGsVnb9",
        "outputId": "ef4bdd90-eb4f-4ebb-b5a3-dad45a779243"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f69be47f-64f2-43bb-84d3-bfb445767bbe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Polarity_Classification</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Their mother always has to deal with her</td>\n",
              "      <td>Neutra</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Kingston's book not only focuses on the upper ...</td>\n",
              "      <td>Neutra</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Just read this book today! I'm sure you'll rea...</td>\n",
              "      <td>Positiva</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>I hate giving away endings and plots, so I won...</td>\n",
              "      <td>Neutra</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Jack's been working on another book, but is so...</td>\n",
              "      <td>Neutra</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79995</th>\n",
              "      <td>79995</td>\n",
              "      <td>내 생애 최고의 영화 다섯 손가락 안에 드는 영화</td>\n",
              "      <td>Positiva</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79996</th>\n",
              "      <td>79996</td>\n",
              "      <td>여주인공이 더럽게 못생겼지만 영화보는내내 입벌리고 멍하게 보게되었다 아래 말했던것처...</td>\n",
              "      <td>Positiva</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79997</th>\n",
              "      <td>79997</td>\n",
              "      <td>악한 사람이 성공하고 죄의식 따위 사죄 따위 없다. 친자식이 두번 버림받는 드라마</td>\n",
              "      <td>Negativa</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79998</th>\n",
              "      <td>79998</td>\n",
              "      <td>진짜 게실망 초한지 볼껄 후회했음</td>\n",
              "      <td>Negativa</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79999</th>\n",
              "      <td>79999</td>\n",
              "      <td>평점조절용 이건 6~7.2 점 정도가 적당함 나름 흫미진진했고 액션도 좋았는데 개연...</td>\n",
              "      <td>Negativa</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>80000 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f69be47f-64f2-43bb-84d3-bfb445767bbe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f69be47f-64f2-43bb-84d3-bfb445767bbe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f69be47f-64f2-43bb-84d3-bfb445767bbe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       Unnamed: 0  ... Unnamed: 0.1\n",
              "0               0  ...          NaN\n",
              "1               1  ...          NaN\n",
              "2               2  ...          NaN\n",
              "3               3  ...          NaN\n",
              "4               4  ...          NaN\n",
              "...           ...  ...          ...\n",
              "79995       79995  ...          NaN\n",
              "79996       79996  ...          NaN\n",
              "79997       79997  ...          NaN\n",
              "79998       79998  ...          NaN\n",
              "79999       79999  ...          NaN\n",
              "\n",
              "[80000 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "train2=pd.read_csv(\"train2.csv\")\n",
        "train2=train2[:80000]\n",
        "train2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "jGOeJPFKHh5S",
        "outputId": "d3606b72-6d1d-4ea3-c95d-a30a4849f081"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8e3b8175-b026-4f1f-8df3-1ad9fba94718\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Polarity_Classification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Garth Nix's 'Mister Monday' was a highly cleve...</td>\n",
              "      <td>Positiva</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Instead, it appears to have been written by a ...</td>\n",
              "      <td>Negativa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>If you treated him as an equal, he could help ...</td>\n",
              "      <td>Neutra</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Diabola becomes mad and uses her powers to mak...</td>\n",
              "      <td>Negativa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>This is a 361 page book about a boy named Arth...</td>\n",
              "      <td>Neutra</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8245</th>\n",
              "      <td>8245</td>\n",
              "      <td>이걸 영화라고..쓰레기도 이런 쓰레기는..ㅋㅋㅋ</td>\n",
              "      <td>Negativa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8246</th>\n",
              "      <td>8246</td>\n",
              "      <td>이렇게 대충 에로물 비스무리 만들어서 신인들 얼굴 도장이나 찍게 만드는 목적인 것 ...</td>\n",
              "      <td>Negativa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8247</th>\n",
              "      <td>8247</td>\n",
              "      <td>난 왜 보다가 졸앗지..</td>\n",
              "      <td>Negativa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8248</th>\n",
              "      <td>8248</td>\n",
              "      <td>이거 지대론데</td>\n",
              "      <td>Positiva</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8249</th>\n",
              "      <td>8249</td>\n",
              "      <td>사랑은 해방이다!</td>\n",
              "      <td>Negativa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8250 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e3b8175-b026-4f1f-8df3-1ad9fba94718')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8e3b8175-b026-4f1f-8df3-1ad9fba94718 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8e3b8175-b026-4f1f-8df3-1ad9fba94718');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      Unnamed: 0  ... Polarity_Classification\n",
              "0              0  ...                Positiva\n",
              "1              1  ...                Negativa\n",
              "2              2  ...                  Neutra\n",
              "3              3  ...                Negativa\n",
              "4              4  ...                  Neutra\n",
              "...          ...  ...                     ...\n",
              "8245        8245  ...                Negativa\n",
              "8246        8246  ...                Negativa\n",
              "8247        8247  ...                Negativa\n",
              "8248        8248  ...                Positiva\n",
              "8249        8249  ...                Negativa\n",
              "\n",
              "[8250 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "test=pd.read_csv(\"test.csv\")\n",
        "test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "mF7_DFv6Vnd1"
      },
      "outputs": [],
      "source": [
        "#creiamo le liste di train e test. 1.8k train 250 test  \n",
        "train_texts=train2['Sentence']\n",
        "train_labels=train2['Polarity_Classification']\n",
        "test_texts=test['Sentence']\n",
        "test_labels=test['Polarity_Classification']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v10htL_G-OFs"
      },
      "source": [
        "<br><br>\n",
        "\n",
        "## **Split the data into training and test sets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tShbGfG-VMe",
        "outputId": "918d7a08-df5b-4124-e957-29f4afa85170"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80000, 80000, 8250, 8250)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "len(train_texts), len(train_labels), len(test_texts), len(test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-34oep8LNKw"
      },
      "source": [
        "Here's an example of a training label and review:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcxvqUsdf5Sm",
        "outputId": "4091701c-5a20-42f1-d175-a1e87c001cc8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Neutra', 'Their mother always has to deal with her')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "train_labels[0], train_texts[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aow3FPpppZVE"
      },
      "source": [
        "<br><br>\n",
        "\n",
        "## **Encode data for BERT**\n",
        "\n",
        "We're going to transform our texts and labels into a format that BERT (via Huggingface and PyTorch) will understand. This is called *encoding* the data.\n",
        "\n",
        "Here are the steps we need to follow:\n",
        "\n",
        "1. The labels&mdash;in this case, Goodreads genres&mdash;need to be turned into integers rather than strings.\n",
        "\n",
        "2. The texts&mdash;in this case, Goodreads reviews&mdash;need to be truncated if they're more than 512 tokens or padded if they're fewer than 512 tokens. The tokens, or words in the texts, also need to be separated into \"word pieces\" and matched to their embedding vectors.\n",
        "\n",
        "3. We need to add special tokens to help BERT:\n",
        "\n",
        "| BERT special token | Explanation |\n",
        "| --------------| ---------|\n",
        "| [CLS] | Start token of every document. |\n",
        "| [SEP] | Separator between each sentence |\n",
        "| [PAD] | Padding at the end of the document as many times as necessary, up to 512 tokens |\n",
        "|  &#35;&#35; | Start of a \"word piece\" |\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRs0dEIoUZtV"
      },
      "source": [
        "Here we will load `DistilBertTokenizerFast` from the HuggingFace library, which will do all the work of encoding the texts for us. The `tokenizer()` will break word tokens into word pieces, truncate to 512 tokens, and add padding and special BERT tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BEvRqpGVMUD",
        "outputId": "12e3ef66-7c41-4f13-86f9-05312fca16aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/28e5b750bf4f39cc620367720e105de1501cf36ec4ca7029eba82c1d2cc47caf.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n",
            "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/5cbdf121f196be5f1016cb102b197b0c34009e1e658f513515f2eebef9f38093.b33e51591f94f17c238ee9b1fac75b96ff2678cbaed6e108feadb3449d18dc24\n",
            "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/47087d99feeb3bc6184d7576ff089c52f7fbe3219fe48c6c4fa681e617753256.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
            "loading configuration file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/cf37a9dc282a679f121734d06f003625d14cfdaf55c14358c4c0b8e7e2b89ac9.7a727bd85e40715bec919a39cdd6f0aba27a8cd488f2d4e0f512448dcd02bf0f\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-multilingual-cased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.16.2\",\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name) # The model_name needs to match our pre-trained model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oj8X7B30UvSj"
      },
      "source": [
        "Here we will create a map of our labels, or Goodreads genres, to integer keys. We take the unique labels, and then we make a dictionary that associates each label/tag with an integer.\n",
        "\n",
        "**Note:** HuggingFace documentation sometimes refers to \"labels\" as \"tags\" but these are the same thing. We use \"labels\" throughout this notebook for clarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "tSuo8gktjsVR"
      },
      "outputs": [],
      "source": [
        "unique_labels = set(label for label in train_labels)\n",
        "label2id = {label: id for id, label in enumerate(unique_labels)}\n",
        "id2label = {id: label for label, id in label2id.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXNlBgAAJSP7",
        "outputId": "84d975f7-a79a-4a1d-b118-aa28014e80fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Negativa', 'Neutra', 'Positiva'}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "unique_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_iAWMtBpfhj",
        "outputId": "2eddbe63-2b61-490a-d6dd-69a58726f360"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['Negativa', 'Positiva', 'Neutra'])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "label2id.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vle8EgkelwRa",
        "outputId": "19544907-de18-4364-ac33-bf97d1bd813f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys([0, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "id2label.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EraNFBC8VnPu"
      },
      "source": [
        "Now let's encode our texts and labels!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "uDuGq_n4pgZX"
      },
      "outputs": [],
      "source": [
        "train_encodings = tokenizer(train_texts.tolist(), truncation=True, padding=True, max_length=max_length)\n",
        "test_encodings  = tokenizer(test_texts.tolist(), truncation=True, padding=True, max_length=max_length)\n",
        "\n",
        "train_labels_encoded = [label2id[y] for y in train_labels.tolist()]\n",
        "test_labels_encoded  = [label2id[y] for y in test_labels.tolist()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7X1sYEGsWDDh"
      },
      "source": [
        "**Examine a Goodreads review in the training set after encoding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "4A89SN_ppiUP",
        "outputId": "fcd79881-f7ed-4d29-b2d6-62ec90bfc608"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[CLS] Like many of the reviews have already said , this book was vi ##vid ##ly des ##cript ##ive in nature and very all ##uring in plot [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "' '.join(train_encodings[29].tokens[0:100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hvOn9RGWUMm"
      },
      "source": [
        "**Examine a Goodreads review in the test set after encoding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "OafZQFKSwG9E",
        "outputId": "472df7d2-6d26-49c2-9d4d-366896779d44"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"[CLS] Ga ##rth Ni ##x ' s ' Mister Monday ' was a highly c ##lever , creative , and enter ##taining read that had me up into the we ##e hours of the morning following Arthur ' s adventure ##s in the House [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\""
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "' '.join(test_encodings[0].tokens[0:100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jmt15FvW8FR"
      },
      "source": [
        "**Examine the training labels after encoding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciemdVYwwMNz",
        "outputId": "91c5e84c-a5a2-4805-e441-96fa9c24981f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "set(train_labels_encoded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UK1Ngb0wXBz9"
      },
      "source": [
        "**Examine the test labels after encoding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TowwulYQwOff",
        "outputId": "38c6e446-e889-4401-b47e-88c22975f7fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "set(test_labels_encoded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChcEv01TXI7v"
      },
      "source": [
        "<br><br>\n",
        "\n",
        "## **Make a custom Torch dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxWcyj0LXVtY"
      },
      "source": [
        "Here we combine the encoded labels and texts into dataset objects. We use the custom Torch `MyDataSet` class to make a `train_dataset` object from  the `train_encodings` and `train_labels_encoded`. We also make a `test_dataset` object from `test_encodings`, and `test_labels_encoded`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "S4VCU-nepnqF"
      },
      "outputs": [],
      "source": [
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "xyCFH3XEi4Ng"
      },
      "outputs": [],
      "source": [
        "train_dataset = MyDataset(train_encodings, train_labels_encoded)\n",
        "test_dataset = MyDataset(test_encodings, test_labels_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "DbJerEgC1Qpc",
        "outputId": "7cf57f06-028a-4b85-ecfe-063469374216"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[CLS] Their mother always has to deal with her [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "' '.join(train_dataset.encodings[0].tokens[0:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "z65jnjVJ1aVB",
        "outputId": "abd109c2-10f3-480b-85ad-a93d1698f406"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"[CLS] Instead , it appears to have been written by a woman with a chip on her shoulder with a pes ##sim ##istic view of society and women ' s abilities to think for themselves [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\""
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "' '.join(test_dataset.encodings[1].tokens[0:100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkVgFcbCqKSu"
      },
      "source": [
        "<br><br>\n",
        "\n",
        "## **Load pre-trained BERT model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2pSuFUVaDhP"
      },
      "source": [
        "Here we load a pre-trained DistilBERT model and send it to CUDA.\n",
        "\n",
        "**Note:** If you decide to repeat fine-tuning after already running the following cells, make sure that you re-run this cell to re-load the original pre-trained model before fine-tuning again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7k75REXp7UJ",
        "outputId": "0e85e820-8ea2-4841-a903-48ebb9757ec0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/cf37a9dc282a679f121734d06f003625d14cfdaf55c14358c4c0b8e7e2b89ac9.7a727bd85e40715bec919a39cdd6f0aba27a8cd488f2d4e0f512448dcd02bf0f\n",
            "Model config DistilBertConfig {\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.16.2\",\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/7b48683e2e7ba71cd1d7d6551ac325eceee01db5c2f3e81cfbfd1ee7bb7877f2.c24097b0cf91dbc66977325325fd03112f0f13d0e3579abbffc8d1e45f8d0619\n",
            "Some weights of the model checkpoint at distilbert-base-multilingual-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# The model_name needs to match the name used for the tokenizer above.\n",
        "model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=len(id2label)).to(device_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRQZuqcAqQNI"
      },
      "source": [
        "<br><br>\n",
        "\n",
        "## **Set the BERT fine-tuning parameters**\n",
        "\n",
        "These are the arguments we'll set in the HuggingFace TrainingArguments objects, which we'll then pass to the HuggingFace Trainer object. There are many more possible arguments, but here we highlight the basics and some common gotchas.\n",
        "\n",
        "When training your own model, you should search over these parameters to find the best settings for your particular dataset. You should use a held-out set of validation data for this step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYOaH9AhbCD_"
      },
      "source": [
        "| Parameter | Explanation |\n",
        "|-----------| ------------|\n",
        "| num_train_epochs | total number of training epochs (how many times to pass through the entire dataset; too much can cause overfitting) |\n",
        "| per_device_train_batch_size | batch size per device during training |\n",
        "| per_device_eval_batch_size |  batch size for evaluation |\n",
        "|  warmup_steps |  number of warmup steps for learning rate scheduler (set lower because of small dataset size) |\n",
        "| weight_decay | strength of weight decay (reduces size of weights, like regularization) |\n",
        "| output_dir | output directory for the fine-tuned model and configuration files |\n",
        "| logging_dir | directory for storing logs |\n",
        "| logging_steps | how often to print logging output (so that we can stop training early if the loss isn't going down) |\n",
        "| evaluation_strategy | evaluate while training so that we can see the accuracy going up |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "3idCswBVg6v_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2945d91f-193d-44bf-e892-34c03aa52ac0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "using `logging_steps` to initialize `eval_steps` to 5000\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    num_train_epochs=2,              # total number of training epochs\n",
        "    per_device_train_batch_size=16,  # batch size per device during training\n",
        "    per_device_eval_batch_size=16,   # batch size for evaluation\n",
        "    learning_rate=3e-5,              # initial learning rate for Adam optimizer\n",
        "    warmup_steps=1000,                # number of warmup steps for learning rate scheduler (set lower because of small dataset size)\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    output_dir='./results',          # output directory\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=5000,               # number of steps to output logging (set lower because of small dataset size)\n",
        "    evaluation_strategy='steps',     # evaluate during fine-tuning so that we can see progress\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Pb3xtidn-HJ"
      },
      "source": [
        "<br><br>\n",
        "\n",
        "## **Fine-tune the BERT model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_SN_oGLV8Vw"
      },
      "source": [
        "First, we define a custom evaluation function that returns the accuracy. You could modify this function to return precision, recall, F1, and/or other metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "pNIt7fcnqUCp"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "  acc = accuracy_score(labels, preds)\n",
        "  return {\n",
        "      'accuracy': acc,\n",
        "  }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9xl5QLmWsAw"
      },
      "source": [
        "Then we create a HuggingFace `Trainer` object using the `TrainingArguments` object that we created above. We also send our `compute_metrics` function to the `Trainer` object, along with our test and train datasets.\n",
        "\n",
        "**Note:** This is what we've been aiming for this whole time! All the work of tokenizing, creating datasets, and setting the training arguments was for this cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "fgc8FS50qV0_"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=test_dataset,           # evaluation dataset (usually a validation set; here we just send our test set)\n",
        "    compute_metrics=compute_metrics      # our custom evaluation function \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mo5QVLYjXGCN"
      },
      "source": [
        "Time to finally fine-tune! \n",
        "\n",
        "Be patient; if you've set everything in Colab to use GPUs, then it should only take a minute or two to run, but if you're running on CPU, it can take hours.\n",
        "\n",
        "After every 10 steps (as we specified in the TrainingArguments object), the trainer will output the current state of the model, including the training loss, validation (\"test\") loss, and accuracy (from our `compute_metrics` function).\n",
        "\n",
        "You should see the loss going down and the accuracy going up. If instead they are staying the same or oscillating, you probably need to change the fine-tuning parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W64JwriVqcmk",
        "outputId": "57f0562c-b320-4a9c-f4e9-76f23650b967"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 80000\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 10000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10000/10000 2:32:48, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.470700</td>\n",
              "      <td>0.352669</td>\n",
              "      <td>0.856000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.312900</td>\n",
              "      <td>0.287623</td>\n",
              "      <td>0.891879</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./results/checkpoint-500\n",
            "Configuration saved in ./results/checkpoint-500/config.json\n",
            "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
            "Saving model checkpoint to ./results/checkpoint-1000\n",
            "Configuration saved in ./results/checkpoint-1000/config.json\n",
            "Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n",
            "Saving model checkpoint to ./results/checkpoint-1500\n",
            "Configuration saved in ./results/checkpoint-1500/config.json\n",
            "Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n",
            "Saving model checkpoint to ./results/checkpoint-2000\n",
            "Configuration saved in ./results/checkpoint-2000/config.json\n",
            "Model weights saved in ./results/checkpoint-2000/pytorch_model.bin\n",
            "Saving model checkpoint to ./results/checkpoint-2500\n",
            "Configuration saved in ./results/checkpoint-2500/config.json\n",
            "Model weights saved in ./results/checkpoint-2500/pytorch_model.bin\n",
            "Saving model checkpoint to ./results/checkpoint-3000\n",
            "Configuration saved in ./results/checkpoint-3000/config.json\n",
            "Model weights saved in ./results/checkpoint-3000/pytorch_model.bin\n",
            "Saving model checkpoint to ./results/checkpoint-3500\n",
            "Configuration saved in ./results/checkpoint-3500/config.json\n",
            "Model weights saved in ./results/checkpoint-3500/pytorch_model.bin\n",
            "Saving model checkpoint to ./results/checkpoint-4000\n",
            "Configuration saved in ./results/checkpoint-4000/config.json\n",
            "Model weights saved in ./results/checkpoint-4000/pytorch_model.bin\n",
            "Saving model checkpoint to ./results/checkpoint-4500\n",
            "Configuration saved in ./results/checkpoint-4500/config.json\n",
            "Model weights saved in ./results/checkpoint-4500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 8250\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-5000\n",
            "Configuration saved in ./results/checkpoint-5000/config.json\n",
            "Model weights saved in ./results/checkpoint-5000/pytorch_model.bin\n",
            "Saving model checkpoint to ./results/checkpoint-5500\n",
            "Configuration saved in ./results/checkpoint-5500/config.json\n",
            "Model weights saved in ./results/checkpoint-5500/pytorch_model.bin\n",
            "Saving model checkpoint to ./results/checkpoint-6000\n",
            "Configuration saved in ./results/checkpoint-6000/config.json\n",
            "Model weights saved in ./results/checkpoint-6000/pytorch_model.bin\n",
            "Saving model checkpoint to ./results/checkpoint-6500\n",
            "Configuration saved in ./results/checkpoint-6500/config.json\n",
            "Model weights saved in ./results/checkpoint-6500/pytorch_model.bin\n",
            "Saving model checkpoint to ./results/checkpoint-7000\n",
            "Configuration saved in ./results/checkpoint-7000/config.json\n",
            "Model weights saved in ./results/checkpoint-7000/pytorch_model.bin\n",
            "Saving model checkpoint to ./results/checkpoint-7500\n",
            "Configuration saved in ./results/checkpoint-7500/config.json\n",
            "Model weights saved in ./results/checkpoint-7500/pytorch_model.bin\n",
            "Saving model checkpoint to ./results/checkpoint-8000\n",
            "Configuration saved in ./results/checkpoint-8000/config.json\n",
            "Model weights saved in ./results/checkpoint-8000/pytorch_model.bin\n",
            "Saving model checkpoint to ./results/checkpoint-8500\n",
            "Configuration saved in ./results/checkpoint-8500/config.json\n",
            "Model weights saved in ./results/checkpoint-8500/pytorch_model.bin\n",
            "Saving model checkpoint to ./results/checkpoint-9000\n",
            "Configuration saved in ./results/checkpoint-9000/config.json\n",
            "Model weights saved in ./results/checkpoint-9000/pytorch_model.bin\n",
            "Saving model checkpoint to ./results/checkpoint-9500\n",
            "Configuration saved in ./results/checkpoint-9500/config.json\n",
            "Model weights saved in ./results/checkpoint-9500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 8250\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-10000\n",
            "Configuration saved in ./results/checkpoint-10000/config.json\n",
            "Model weights saved in ./results/checkpoint-10000/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=10000, training_loss=0.391808203125, metrics={'train_runtime': 9169.5214, 'train_samples_per_second': 17.449, 'train_steps_per_second': 1.091, 'total_flos': 1.295719850016e+16, 'train_loss': 0.391808203125, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "trainer.train() #con 80k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXeIZ_LFqeps"
      },
      "source": [
        "<br><br>\n",
        "\n",
        "## **Save fine-tuned model**\n",
        "\n",
        "The following cell will save the model and its configuration files to a directory in Colab. To preserve this model for future use, you should download the model to your computer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "kxkDWDfvqeAo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9f22422-3f3f-4ada-b690-1f131459070b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to Polarity_2c\n",
            "Configuration saved in Polarity_2c/config.json\n",
            "Model weights saved in Polarity_2c/pytorch_model.bin\n"
          ]
        }
      ],
      "source": [
        "trainer.save_model(cached_model_directory_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epiLftYkZrzc"
      },
      "source": [
        "(Optional) If you've already fine-tuned and saved the model, you can reload it using the following line. You don't have to run fine-tuning every time you want to evaluate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpzV4hFsLmZ6"
      },
      "source": [
        "<br><br>\n",
        "\n",
        "## **Evaluate fine-tuned model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IvfhrBtYYcz"
      },
      "source": [
        "The following function of the `Trainer` object will run the built-in evaluation, including our `compute_metrics` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "dshtTH0WLtM1",
        "outputId": "2ad20708-630e-4c2d-cc98-dc90ae696ddf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 8250\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='516' max='516' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [516/516 02:04]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 2.0,\n",
              " 'eval_accuracy': 0.8918787878787878,\n",
              " 'eval_loss': 0.2876233160495758,\n",
              " 'eval_runtime': 124.7971,\n",
              " 'eval_samples_per_second': 66.107,\n",
              " 'eval_steps_per_second': 4.135}"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILJGLcCjYhPt"
      },
      "source": [
        "But we might want to do more fine-grained analysis of the model, so we extract the predicted labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "v_E8oVjeLuv2",
        "outputId": "8012c184-f031-4aa8-821a-5b9b6ad874df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 8250\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1032' max='516' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [516/516 04:09]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "predicted_results = trainer.predict(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUYGfzczOuJE",
        "outputId": "ad677cdf-ea7f-45eb-af98-d56588a2f3bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8250, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "predicted_results.predictions.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "hqUTa5irLyN8"
      },
      "outputs": [],
      "source": [
        "predicted_labels = predicted_results.predictions.argmax(-1) # Get the highest probability prediction\n",
        "predicted_labels = predicted_labels.flatten().tolist()      # Flatten the predictions into a 1D list\n",
        "predicted_labels = [id2label[l] for l in predicted_labels]  # Convert from integers back to strings for readability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2jtqnJbPMpu",
        "outputId": "f81d153a-ea74-4d81-d0de-1d878d4eace2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8250"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "len(predicted_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVcMU45fLzli",
        "outputId": "558e3785-2eca-4561-dae2-de518279a6b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negativa       0.89      0.89      0.89      3617\n",
            "      Neutra       0.78      0.71      0.74       469\n",
            "    Positiva       0.90      0.91      0.91      4164\n",
            "\n",
            "    accuracy                           0.89      8250\n",
            "   macro avg       0.86      0.84      0.85      8250\n",
            "weighted avg       0.89      0.89      0.89      8250\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(test_labels, \n",
        "                            predicted_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmxEWmKYZf9a"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4J4pxn9NCC1_"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XtUaMCjCC2A"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "va8kkMblCC2A"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-KOk7iACC2A"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2B8gNceCC2B"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "iP_6qeODBnt7"
      },
      "outputs": [],
      "source": [
        "def prediction_test(dataset,modello):  #dataset fa riferimento al set di dati che vogliamo passare, modello dipende dal tipo di FT\n",
        "#poi ci sarà anche la funzione per predire senza labels\n",
        "    tok = DistilBertTokenizerFast.from_pretrained('distilbert-base-multilingual-cased')\n",
        "    test_texts=dataset['Sentence']\n",
        "    test_labels=dataset['Polarity_Classification']\n",
        "\n",
        "#unique_labels = set(label for label in test_labels)\n",
        "#label2id = {label: id for id, label in enumerate(unique_labels)}\n",
        "#id2label = {id: label for label, id in label2id.items()}\n",
        "    unique_labels={'Neutra', 'Positiva', 'Negativa'}\n",
        "    label2id={'Negativa': 0, 'Neutra': 2, 'Positiva': 1}\n",
        "    id2label={0:'Negativa', 2:'Neutra', 1:'Positiva'}\n",
        "\n",
        "#train_encodings = tok(train_texts.tolist(), truncation=True, padding=True, max_length=max_length)\n",
        "    test_encodings  = tok(test_texts.tolist(), truncation=True, padding=True, max_length=max_length)\n",
        "\n",
        "#train_labels_encoded = [label2id[y] for y in train_labels.tolist()]\n",
        "    test_labels_encoded  = [label2id[y] for y in test_labels.tolist()]\n",
        "    \n",
        "\n",
        "    class MyDataset(torch.utils.data.Dataset):\n",
        "        def __init__(self, encodings, labels):\n",
        "            self.encodings = encodings\n",
        "            self.labels = labels\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "            item['labels'] = torch.tensor(self.labels[idx])\n",
        "            return item\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.labels)\n",
        "\n",
        "#train_dataset = MyDataset(train_encodings, train_labels_encoded)\n",
        "    test_dataset = MyDataset(test_encodings, test_labels_encoded)\n",
        "    \n",
        "    trainer = Trainer(model=modello)  #basta avere il modello come parametro\n",
        "\n",
        "    predicted_results=trainer.predict(test_dataset)\n",
        "    \n",
        "    predicted_labels = predicted_results.predictions.argmax(-1) # Get the highest probability prediction\n",
        "    predicted_labels = predicted_labels.flatten().tolist()      # Flatten the predictions into a 1D list\n",
        "    predicted_labels = [id2label[l] for l in predicted_labels]  # Convert from integers back to strings for readability\n",
        "\n",
        "#len(predicted_labels)\n",
        "\n",
        "    return print(classification_report(test_labels,predicted_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwfx6FzVBnt7"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYvmLw_yBnt7"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20F56JNrs62D"
      },
      "outputs": [],
      "source": [
        "#RELOAD THE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVFVfy0ws62D",
        "outputId": "91d290e1-343c-4ac4-d797-dcddffcee386"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/28e5b750bf4f39cc620367720e105de1501cf36ec4ca7029eba82c1d2cc47caf.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n",
            "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/5cbdf121f196be5f1016cb102b197b0c34009e1e658f513515f2eebef9f38093.b33e51591f94f17c238ee9b1fac75b96ff2678cbaed6e108feadb3449d18dc24\n",
            "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/47087d99feeb3bc6184d7576ff089c52f7fbe3219fe48c6c4fa681e617753256.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
            "loading configuration file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/cf37a9dc282a679f121734d06f003625d14cfdaf55c14358c4c0b8e7e2b89ac9.7a727bd85e40715bec919a39cdd6f0aba27a8cd488f2d4e0f512448dcd02bf0f\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-multilingual-cased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.16.2\",\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n",
            "loading configuration file Polarity_2c/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-multilingual-cased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.16.2\",\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n",
            "loading weights file Polarity_2c/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
            "\n",
            "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at Polarity_2c.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
        "#tok = DistilBertTokenizerFast.from_pretrained(model_name) # The model_name needs to match our pre-trained model.\n",
        "tok = DistilBertTokenizerFast.from_pretrained(model_name) # The model_name needs to match our pre-trained model.\n",
        "mod = DistilBertForSequenceClassification.from_pretrained(cached_model_directory_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BDtPZubs62F"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyB3NCl4q8oP"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 873
        },
        "id": "oGv2FlCebeMz",
        "outputId": "b760b890-7f6f-4651-b61c-4733a63be305"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/28e5b750bf4f39cc620367720e105de1501cf36ec4ca7029eba82c1d2cc47caf.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n",
            "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/5cbdf121f196be5f1016cb102b197b0c34009e1e658f513515f2eebef9f38093.b33e51591f94f17c238ee9b1fac75b96ff2678cbaed6e108feadb3449d18dc24\n",
            "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/47087d99feeb3bc6184d7576ff089c52f7fbe3219fe48c6c4fa681e617753256.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
            "loading configuration file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/cf37a9dc282a679f121734d06f003625d14cfdaf55c14358c4c0b8e7e2b89ac9.7a727bd85e40715bec919a39cdd6f0aba27a8cd488f2d4e0f512448dcd02bf0f\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-multilingual-cased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.16.2\",\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n",
            "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "***** Running Prediction *****\n",
            "  Num examples = 615\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [77/77 00:04]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negativa       0.71      0.50      0.59        98\n",
            "      Neutra       0.78      0.85      0.81       274\n",
            "    Positiva       0.83      0.85      0.84       243\n",
            "\n",
            "    accuracy                           0.79       615\n",
            "   macro avg       0.77      0.73      0.75       615\n",
            "weighted avg       0.79      0.79      0.79       615\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prediction_test(test[:615],mod)   #tabella per inglesi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2RZv-Y0beM1"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQevi6vrbeM2"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jowBlG9AVeI2"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vv2Ml8fJVeK2"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 873
        },
        "id": "zf7Gm3CTVeM-",
        "outputId": "6051be0f-772c-4773-cba4-1f652f5e19c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/28e5b750bf4f39cc620367720e105de1501cf36ec4ca7029eba82c1d2cc47caf.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n",
            "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/5cbdf121f196be5f1016cb102b197b0c34009e1e658f513515f2eebef9f38093.b33e51591f94f17c238ee9b1fac75b96ff2678cbaed6e108feadb3449d18dc24\n",
            "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/47087d99feeb3bc6184d7576ff089c52f7fbe3219fe48c6c4fa681e617753256.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
            "loading configuration file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/cf37a9dc282a679f121734d06f003625d14cfdaf55c14358c4c0b8e7e2b89ac9.7a727bd85e40715bec919a39cdd6f0aba27a8cd488f2d4e0f512448dcd02bf0f\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-multilingual-cased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.16.2\",\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n",
            "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "***** Running Prediction *****\n",
            "  Num examples = 3635\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='455' max='455' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [455/455 00:55]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negativa       0.92      0.94      0.93      1517\n",
            "      Neutra       0.79      0.51      0.62       195\n",
            "    Positiva       0.94      0.96      0.95      1923\n",
            "\n",
            "    accuracy                           0.93      3635\n",
            "   macro avg       0.88      0.80      0.83      3635\n",
            "weighted avg       0.93      0.93      0.93      3635\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prediction_test(test[615:4250],mod)   #tabella per italiane, domain social media e hotel reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "gKkmz6tqVeWb"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "dKlsoP9KbeM4"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "aZzWu78Nq82e"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "2yMRdNk3V4aA"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 855
        },
        "id": "IWLdyt_bV4cL",
        "outputId": "8687667a-d22f-4e21-eea4-18872ed95b54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/28e5b750bf4f39cc620367720e105de1501cf36ec4ca7029eba82c1d2cc47caf.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n",
            "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/5cbdf121f196be5f1016cb102b197b0c34009e1e658f513515f2eebef9f38093.b33e51591f94f17c238ee9b1fac75b96ff2678cbaed6e108feadb3449d18dc24\n",
            "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/47087d99feeb3bc6184d7576ff089c52f7fbe3219fe48c6c4fa681e617753256.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
            "loading configuration file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/cf37a9dc282a679f121734d06f003625d14cfdaf55c14358c4c0b8e7e2b89ac9.7a727bd85e40715bec919a39cdd6f0aba27a8cd488f2d4e0f512448dcd02bf0f\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-multilingual-cased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.16.2\",\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n",
            "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "***** Running Prediction *****\n",
            "  Num examples = 4000\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [500/500 00:31]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negativa       0.88      0.87      0.87      2002\n",
            "    Positiva       0.87      0.88      0.87      1998\n",
            "\n",
            "    accuracy                           0.87      4000\n",
            "   macro avg       0.87      0.87      0.87      4000\n",
            "weighted avg       0.87      0.87      0.87      4000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prediction_test(test[4250:],mod)   #tabella per koreane, domain movie reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "iQw39j45V4eK"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "je4Y1-z9V4iX"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqL1PeMkV4kk"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88xVgdxwq8sI"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTfGMhCGq8um"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbM4ckOYq8xQ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3uAV8AM7q8zg"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1Pa0bkTHc5sR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oVBgcJG_c5ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sW59andmc5wX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pe9WtiaTc5y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tbBiY-l0c50v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Uc6P3jqlc54M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Es-aUsa2ZgIc"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZWrk5hwCC2B"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9v04bOpvCC2B"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbPiEkNnCC2C"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "FineTuning_Polarity2-Copy2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}