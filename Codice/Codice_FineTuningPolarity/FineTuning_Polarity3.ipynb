{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y73xWUkpU1AC"
   },
   "source": [
    "<br><br>\n",
    "\n",
    "## **Import necessary Python libraries and modules**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJ9kmfrO3M_w"
   },
   "source": [
    "First, we will import necessary Python libraries and modules. These include as `gdown`, for downloading large files from Google Drive (where we will get our UCSD Goodreads reviews), as well as scikit-learn (`sklearn`) and PyTorch (`torch`), for various machine learning tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "x9Si6kIWcULv"
   },
   "outputs": [],
   "source": [
    "\n",
    "# For data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For machine learning tools and evaluation\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "\n",
    "\n",
    "# For deep learning\n",
    "# https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4N0RIalt28yL"
   },
   "source": [
    "To use the HuggingFace [`transformers` Python library](https://huggingface.co/transformers/installation.html), we will install it with `pip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BNxmMnzoccfm",
    "outputId": "a85455b0-878e-4c60-e3e6-201d1894ed4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.5 MB 5.4 MB/s \n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67 kB 4.4 MB/s \n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,>=0.10.1\n",
      "  Downloading tokenizers-0.11.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.8 MB 26.2 MB/s \n",
      "\u001b[?25hCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 895 kB 10.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.1)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 596 kB 34.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.4 transformers-4.16.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f29CPpKi3__Q"
   },
   "source": [
    "Once `transformers` is installed, we will import modules for `DistilBert`, a *distilled* or smaller version of a BERT model that runs more quickly and uses less computing power. This makes it ideal for those just getting started with BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8ARMrKfmceAb"
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q70KYS_NVSDL"
   },
   "source": [
    "<br><br>\n",
    "\n",
    "## **Set parameters and file paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "piWsW9ZeaP_D"
   },
   "outputs": [],
   "source": [
    "# This is the name of the BERT model that we want to use. \n",
    "# We're using DistilBERT to save space (it's a distilled version of the full BERT model), \n",
    "# and we're going to use the cased (vs uncased) version.\n",
    "model_name = 'distilbert-base-multilingual-cased'  \n",
    "\n",
    "# This is the name of the program management system for NVIDIA GPUs. We're going to send our code here.\n",
    "device_name = 'cuda'       \n",
    "\n",
    "# This is the maximum number of tokens in any document sent to BERT.\n",
    "max_length = 512                                                        \n",
    "\n",
    "# This is the name of the directory where we'll save our model. You can name it whatever you want.\n",
    "#cached_model_directory_name = 'ABSA_FineTuning_BERT'  \n",
    "cached_model_directory_name = 'Polarity_3'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "mVgnQsf9VnYE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7P5FuT-DWnMm",
    "outputId": "0c522891-ce04-4d65-b88b-06a9a2b0a5af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla K80\n"
     ]
    }
   ],
   "source": [
    "#stiamo utlizzando la GPU?\n",
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "X83oPpGsVnb9",
    "outputId": "fb5622a7-b16f-4cf2-ad86-a12c01284909"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Polarity_Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Their mother always has to deal with her</td>\n",
       "      <td>Neutra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Kingston's book not only focuses on the upper ...</td>\n",
       "      <td>Neutra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Just read this book today! I'm sure you'll rea...</td>\n",
       "      <td>Positiva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I hate giving away endings and plots, so I won...</td>\n",
       "      <td>Neutra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Jack's been working on another book, but is so...</td>\n",
       "      <td>Neutra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18496</th>\n",
       "      <td>18496</td>\n",
       "      <td>Ïò§Îäò Ïã¨ÏÇ¨ÏúÑÏõêÎì§ ÌäπÌûà Î∞ïÏßÑÏòÅÏã¨ÏÇ¨Ïóê ÎààÏÇ¥Ïù¥ Ï∞åÌë∏Î†§Ï°åÎã§ ÏïåÎßπÏÜîÏßÅÌûà Ïã§Î†•Î©¥ÏóêÏÑúÎäî ÏõîÎì±ÌïòÎã§...</td>\n",
       "      <td>Negativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18497</th>\n",
       "      <td>18497</td>\n",
       "      <td>Î≥ÑÎ°ú,,ÎÑàÎ¨¥ ÏñµÏßÄÍ∞ôÎã§</td>\n",
       "      <td>Negativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18498</th>\n",
       "      <td>18498</td>\n",
       "      <td>Ï¥àÎî©ÎèÑ Ïù¥Îü∞Í±∞ ÏïàÎ≥¥Í≤†Îã§.</td>\n",
       "      <td>Negativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18499</th>\n",
       "      <td>18499</td>\n",
       "      <td>Ïû¨ÎØ∏ÏûàÏóàÎã§</td>\n",
       "      <td>Positiva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18500</th>\n",
       "      <td>18500</td>\n",
       "      <td>Ï†ïÎßê. Ïù¥Í≤å Î≠îÍ∞Ä ÌñàÏùå. ÏãúÏÇ¨ÌöåÏóêÏÑú ÏãúÍ∞ÑÏù¥ ÏïÑÍπåÏõåÎ≥∏Ï†ÅÏùÄ Ï†ïÎßê Ïò§ÎûúÎßå-_„Ö†</td>\n",
       "      <td>Negativa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18501 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                           Sentence  \\\n",
       "0               0           Their mother always has to deal with her   \n",
       "1               1  Kingston's book not only focuses on the upper ...   \n",
       "2               2  Just read this book today! I'm sure you'll rea...   \n",
       "3               3  I hate giving away endings and plots, so I won...   \n",
       "4               4  Jack's been working on another book, but is so...   \n",
       "...           ...                                                ...   \n",
       "18496       18496  Ïò§Îäò Ïã¨ÏÇ¨ÏúÑÏõêÎì§ ÌäπÌûà Î∞ïÏßÑÏòÅÏã¨ÏÇ¨Ïóê ÎààÏÇ¥Ïù¥ Ï∞åÌë∏Î†§Ï°åÎã§ ÏïåÎßπÏÜîÏßÅÌûà Ïã§Î†•Î©¥ÏóêÏÑúÎäî ÏõîÎì±ÌïòÎã§...   \n",
       "18497       18497                                        Î≥ÑÎ°ú,,ÎÑàÎ¨¥ ÏñµÏßÄÍ∞ôÎã§   \n",
       "18498       18498                                      Ï¥àÎî©ÎèÑ Ïù¥Îü∞Í±∞ ÏïàÎ≥¥Í≤†Îã§.   \n",
       "18499       18499                                              Ïû¨ÎØ∏ÏûàÏóàÎã§   \n",
       "18500       18500           Ï†ïÎßê. Ïù¥Í≤å Î≠îÍ∞Ä ÌñàÏùå. ÏãúÏÇ¨ÌöåÏóêÏÑú ÏãúÍ∞ÑÏù¥ ÏïÑÍπåÏõåÎ≥∏Ï†ÅÏùÄ Ï†ïÎßê Ïò§ÎûúÎßå-_„Ö†   \n",
       "\n",
       "      Polarity_Classification  \n",
       "0                      Neutra  \n",
       "1                      Neutra  \n",
       "2                    Positiva  \n",
       "3                      Neutra  \n",
       "4                      Neutra  \n",
       "...                       ...  \n",
       "18496                Negativa  \n",
       "18497                Negativa  \n",
       "18498                Negativa  \n",
       "18499                Positiva  \n",
       "18500                Negativa  \n",
       "\n",
       "[18501 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train3=pd.read_csv(\"C:\\\\Users\\\\Fossati\\\\Desktop\\\\Tesi\\\\Dati\\\\Dati_FineTuningBERT\\\\Train_test_polarity\\\\train3.csv\")\n",
    "train3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "jGOeJPFKHh5S",
    "outputId": "7a894dad-043d-4e60-903a-9cf680c415df"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Polarity_Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Garth Nix's 'Mister Monday' was a highly cleve...</td>\n",
       "      <td>Positiva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Instead, it appears to have been written by a ...</td>\n",
       "      <td>Negativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>If you treated him as an equal, he could help ...</td>\n",
       "      <td>Neutra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Diabola becomes mad and uses her powers to mak...</td>\n",
       "      <td>Negativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>This is a 361 page book about a boy named Arth...</td>\n",
       "      <td>Neutra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8245</th>\n",
       "      <td>8245</td>\n",
       "      <td>Ïù¥Í±∏ ÏòÅÌôîÎùºÍ≥†..Ïì∞Î†àÍ∏∞ÎèÑ Ïù¥Îü∞ Ïì∞Î†àÍ∏∞Îäî..„Öã„Öã„Öã</td>\n",
       "      <td>Negativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8246</th>\n",
       "      <td>8246</td>\n",
       "      <td>Ïù¥Î†áÍ≤å ÎåÄÏ∂© ÏóêÎ°úÎ¨º ÎπÑÏä§Î¨¥Î¶¨ ÎßåÎì§Ïñ¥ÏÑú Ïã†Ïù∏Îì§ ÏñºÍµ¥ ÎèÑÏû•Ïù¥ÎÇò Ï∞çÍ≤å ÎßåÎìúÎäî Î™©Ï†ÅÏù∏ Í≤É ...</td>\n",
       "      <td>Negativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8247</th>\n",
       "      <td>8247</td>\n",
       "      <td>ÎÇú Ïôú Î≥¥Îã§Í∞Ä Ï°∏ÏïóÏßÄ..</td>\n",
       "      <td>Negativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8248</th>\n",
       "      <td>8248</td>\n",
       "      <td>Ïù¥Í±∞ ÏßÄÎåÄÎ°†Îç∞</td>\n",
       "      <td>Positiva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8249</th>\n",
       "      <td>8249</td>\n",
       "      <td>ÏÇ¨ÎûëÏùÄ Ìï¥Î∞©Ïù¥Îã§!</td>\n",
       "      <td>Negativa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8250 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                           Sentence  \\\n",
       "0              0  Garth Nix's 'Mister Monday' was a highly cleve...   \n",
       "1              1  Instead, it appears to have been written by a ...   \n",
       "2              2  If you treated him as an equal, he could help ...   \n",
       "3              3  Diabola becomes mad and uses her powers to mak...   \n",
       "4              4  This is a 361 page book about a boy named Arth...   \n",
       "...          ...                                                ...   \n",
       "8245        8245                         Ïù¥Í±∏ ÏòÅÌôîÎùºÍ≥†..Ïì∞Î†àÍ∏∞ÎèÑ Ïù¥Îü∞ Ïì∞Î†àÍ∏∞Îäî..„Öã„Öã„Öã   \n",
       "8246        8246  Ïù¥Î†áÍ≤å ÎåÄÏ∂© ÏóêÎ°úÎ¨º ÎπÑÏä§Î¨¥Î¶¨ ÎßåÎì§Ïñ¥ÏÑú Ïã†Ïù∏Îì§ ÏñºÍµ¥ ÎèÑÏû•Ïù¥ÎÇò Ï∞çÍ≤å ÎßåÎìúÎäî Î™©Ï†ÅÏù∏ Í≤É ...   \n",
       "8247        8247                                      ÎÇú Ïôú Î≥¥Îã§Í∞Ä Ï°∏ÏïóÏßÄ..   \n",
       "8248        8248                                            Ïù¥Í±∞ ÏßÄÎåÄÎ°†Îç∞   \n",
       "8249        8249                                          ÏÇ¨ÎûëÏùÄ Ìï¥Î∞©Ïù¥Îã§!   \n",
       "\n",
       "     Polarity_Classification  \n",
       "0                   Positiva  \n",
       "1                   Negativa  \n",
       "2                     Neutra  \n",
       "3                   Negativa  \n",
       "4                     Neutra  \n",
       "...                      ...  \n",
       "8245                Negativa  \n",
       "8246                Negativa  \n",
       "8247                Negativa  \n",
       "8248                Positiva  \n",
       "8249                Negativa  \n",
       "\n",
       "[8250 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=pd.read_csv(\"C:\\\\Users\\\\Fossati\\\\Desktop\\\\Tesi\\\\Dati\\\\Dati_FineTuningBERT\\\\Train_test_polarity\\\\test.csv\")\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "mF7_DFv6Vnd1"
   },
   "outputs": [],
   "source": [
    "#creiamo le liste di train e test. 1.8k train 250 test  \n",
    "train_texts=train3['Sentence']\n",
    "train_labels=train3['Polarity_Classification']\n",
    "test_texts=test['Sentence']\n",
    "test_labels=test['Polarity_Classification']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v10htL_G-OFs"
   },
   "source": [
    "<br><br>\n",
    "\n",
    "## **Split the data into training and test sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4tShbGfG-VMe",
    "outputId": "fe2c31e2-b32c-4eb2-f410-1161c09679c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18501, 18501, 8250, 8250)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_texts), len(train_labels), len(test_texts), len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-34oep8LNKw"
   },
   "source": [
    "Here's an example of a training label and review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dcxvqUsdf5Sm",
    "outputId": "6a5eabc9-539a-4f43-80c4-2be2f0d47962"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Neutra', 'Their mother always has to deal with her')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0], train_texts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aow3FPpppZVE"
   },
   "source": [
    "<br><br>\n",
    "\n",
    "## **Encode data for BERT**\n",
    "\n",
    "We're going to transform our texts and labels into a format that BERT (via Huggingface and PyTorch) will understand. This is called *encoding* the data.\n",
    "\n",
    "Here are the steps we need to follow:\n",
    "\n",
    "1. The labels&mdash;in this case, Goodreads genres&mdash;need to be turned into integers rather than strings.\n",
    "\n",
    "2. The texts&mdash;in this case, Goodreads reviews&mdash;need to be truncated if they're more than 512 tokens or padded if they're fewer than 512 tokens. The tokens, or words in the texts, also need to be separated into \"word pieces\" and matched to their embedding vectors.\n",
    "\n",
    "3. We need to add special tokens to help BERT:\n",
    "\n",
    "| BERT special token | Explanation |\n",
    "| --------------| ---------|\n",
    "| [CLS] | Start token of every document. |\n",
    "| [SEP] | Separator between each sentence |\n",
    "| [PAD] | Padding at the end of the document as many times as necessary, up to 512 tokens |\n",
    "|  &#35;&#35; | Start of a \"word piece\" |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GRs0dEIoUZtV"
   },
   "source": [
    "Here we will load `DistilBertTokenizerFast` from the HuggingFace library, which will do all the work of encoding the texts for us. The `tokenizer()` will break word tokens into word pieces, truncate to 512 tokens, and add padding and special BERT tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "b2d62e9094824163b99554f768975c4e",
      "e2c27467ea0c462f8a35bd756d0928df",
      "e501e57fc2194e27a0dfc3094d8cd0f1",
      "fedf6d6698ce4ce8b77f2cc24013dc5a",
      "9b357745818e4db59fa6b6fe5fbe3069",
      "df013c2043a14cdebd80aa2f91db14be",
      "dda42200f55a410eab281a0e6d4ad866",
      "838723b7b46e46bfaf9acf1998017114",
      "16f5b986cad6491c8b5fa08d9b4e98cd",
      "62365c5fe15c42f39e8f8a8ab32d8384",
      "1fc10461908a410c98c17cc31bdc2f58",
      "e434b5890bc048318041b62b3878566b",
      "7feade48a94843efaa49814a0ce7efcb",
      "aa1c1d05c6774ca5a34ec4471f9e8d19",
      "ddabf3a6ed5d4069b435a315fc71878b",
      "8469d4a936a4412685ce08350ed517d3",
      "87bbbf8803114dfcafcce89958d01ca8",
      "d7df69d3039e40ed8c7a28007567a74b",
      "4e9d577ac7f244c39acd1146bfb9d0ce",
      "84b1165e342c4dcab8a16955c51c9e04",
      "9b894ceb2a93460ebdcc65682e00cea1",
      "51d13f8f59c84ea5b678eab69458ccbf",
      "4358b7c34dd94d88813065447b0e3d3a",
      "912097536125434c88e43a15fbb0568c",
      "fb0fdc1432a44416a5aa1f2f9f0963be",
      "a679d4cf3072407fa42bf4f53e4b193b",
      "845df591a09a49bebc5d032328816223",
      "21e3089bb9ab4f94aaa415fcefa2c7e9",
      "428fc073b24048f8a172d4e3ac904528",
      "f88f3486e31d43f8a9ba81a2ef345f01",
      "66bb7c0d8c7d412b8f3c4bbb11f51dc3",
      "9621c21eae2541569bdd5a212aa610e1",
      "e02abb54586a42d381a105558b3a693e",
      "a3159f042f4d4798a5f82b1a5175c0dd",
      "2bd7687d5f614c87a73047d271c57f81",
      "ca486e16524d4547960ab7841f810164",
      "b1e7939eb1ea484a9e393b93abc83905",
      "0a8eb73c68d64512833319bf638b21fb",
      "6a9fab4494e346749cffa129cc804c2f",
      "c7233912eb52420c903e7f6313839fb1",
      "16b6a7526a454896ae8e747d8c69d40d",
      "472714479e9c4e8587e5d1799ab8e463",
      "6116d2245f0b4c45899cf80f8a741891",
      "36cfcac443294355aff5aea1dc1e82a2"
     ]
    },
    "id": "9BEvRqpGVMUD",
    "outputId": "420cfc10-2352-4b4a-afb2-293e6549e9b4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2d62e9094824163b99554f768975c4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e434b5890bc048318041b62b3878566b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/972k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4358b7c34dd94d88813065447b0e3d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.87M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3159f042f4d4798a5f82b1a5175c0dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name) # The model_name needs to match our pre-trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oj8X7B30UvSj"
   },
   "source": [
    "Here we will create a map of our labels, or Goodreads genres, to integer keys. We take the unique labels, and then we make a dictionary that associates each label/tag with an integer.\n",
    "\n",
    "**Note:** HuggingFace documentation sometimes refers to \"labels\" as \"tags\" but these are the same thing. We use \"labels\" throughout this notebook for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "tSuo8gktjsVR"
   },
   "outputs": [],
   "source": [
    "unique_labels={'Neutra', 'Positiva', 'Negativa'}\n",
    "label2id={'Negativa': 2, 'Neutra': 0, 'Positiva': 1}\n",
    "id2label={2:'Negativa', 0:'Neutra', 1:'Positiva'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xXNlBgAAJSP7",
    "outputId": "9f10fc4e-69e7-4c78-cbfe-2188ce1eba62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Negativa', 'Neutra', 'Positiva'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M_iAWMtBpfhj",
    "outputId": "f16531ef-1e5c-46c4-ff91-9cb37099c6b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Negativa', 'Neutra', 'Positiva'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vle8EgkelwRa",
    "outputId": "f02fdb50-72db-45f2-cae3-e33dfa028f9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([2, 0, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EraNFBC8VnPu"
   },
   "source": [
    "Now let's encode our texts and labels!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "uDuGq_n4pgZX"
   },
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_texts.tolist(), truncation=True, padding=True, max_length=max_length)\n",
    "test_encodings  = tokenizer(test_texts.tolist(), truncation=True, padding=True, max_length=max_length)\n",
    "\n",
    "train_labels_encoded = [label2id[y] for y in train_labels.tolist()]\n",
    "test_labels_encoded  = [label2id[y] for y in test_labels.tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7X1sYEGsWDDh"
   },
   "source": [
    "**Examine a Goodreads review in the training set after encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "4A89SN_ppiUP",
    "outputId": "ec6d7cc3-4979-4f5b-f27f-918d13cd7d1b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'[CLS] Like many of the reviews have already said , this book was vi ##vid ##ly des ##cript ##ive in nature and very all ##uring in plot [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_encodings[29].tokens[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3hvOn9RGWUMm"
   },
   "source": [
    "**Examine a Goodreads review in the test set after encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "OafZQFKSwG9E",
    "outputId": "eb0ae3e8-73d3-4745-dcb7-3e6d39d60571"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"[CLS] Ga ##rth Ni ##x ' s ' Mister Monday ' was a highly c ##lever , creative , and enter ##taining read that had me up into the we ##e hours of the morning following Arthur ' s adventure ##s in the House [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(test_encodings[0].tokens[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jmt15FvW8FR"
   },
   "source": [
    "**Examine the training labels after encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ciemdVYwwMNz",
    "outputId": "ec5a6130-e46e-4ce4-c905-d7f6752f8401"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_labels_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UK1Ngb0wXBz9"
   },
   "source": [
    "**Examine the test labels after encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TowwulYQwOff",
    "outputId": "b16d44cf-d149-47c4-9cfc-1b4a8596d1df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(test_labels_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ChcEv01TXI7v"
   },
   "source": [
    "<br><br>\n",
    "\n",
    "## **Make a custom Torch dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PxWcyj0LXVtY"
   },
   "source": [
    "Here we combine the encoded labels and texts into dataset objects. We use the custom Torch `MyDataSet` class to make a `train_dataset` object from  the `train_encodings` and `train_labels_encoded`. We also make a `test_dataset` object from `test_encodings`, and `test_labels_encoded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "S4VCU-nepnqF"
   },
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "xyCFH3XEi4Ng"
   },
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(train_encodings, train_labels_encoded)\n",
    "test_dataset = MyDataset(test_encodings, test_labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "DbJerEgC1Qpc",
    "outputId": "8768f9b1-8b21-4f76-fd22-e6bde20eb32c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'[CLS] Their mother always has to deal with her [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_dataset.encodings[0].tokens[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "z65jnjVJ1aVB",
    "outputId": "99609baa-be08-439a-8827-5a320f76a74b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"[CLS] Instead , it appears to have been written by a woman with a chip on her shoulder with a pes ##sim ##istic view of society and women ' s abilities to think for themselves [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(test_dataset.encodings[1].tokens[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OkVgFcbCqKSu"
   },
   "source": [
    "<br><br>\n",
    "\n",
    "## **Load pre-trained BERT model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2pSuFUVaDhP"
   },
   "source": [
    "Here we load a pre-trained DistilBERT model and send it to CUDA.\n",
    "\n",
    "**Note:** If you decide to repeat fine-tuning after already running the following cells, make sure that you re-run this cell to re-load the original pre-trained model before fine-tuning again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156,
     "referenced_widgets": [
      "e00864cc625d4caa800153e937725da7",
      "0cdfee14eb504f5f9f31cc2adb6aa7ae",
      "042cc51b95ed459cb55708ad348cdffe",
      "2aa7cea2f2ce490cafdfa020518476d7",
      "21c73885b0c548da9141a8d7f1e86b1d",
      "c9aef65bcc4248beb37db33c9b8d72c2",
      "47c17838fbd14e548875e6353ef7bac6",
      "b64c9fb4b04a45cf80c9459a1303e32b",
      "43ca0fa1e42c4be89f1a9018e8ad1c88",
      "d3c16ea0f0bc40318a07d71301df490b",
      "affbbba6f0a74e68b4f6f3e7e30cf425"
     ]
    },
    "id": "a7k75REXp7UJ",
    "outputId": "8d8282ed-2105-4cd4-c5db-7941673ebf15"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e00864cc625d4caa800153e937725da7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/517M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-multilingual-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# The model_name needs to match the name used for the tokenizer above.\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=len(id2label)).to(device_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VRQZuqcAqQNI"
   },
   "source": [
    "<br><br>\n",
    "\n",
    "## **Set the BERT fine-tuning parameters**\n",
    "\n",
    "These are the arguments we'll set in the HuggingFace TrainingArguments objects, which we'll then pass to the HuggingFace Trainer object. There are many more possible arguments, but here we highlight the basics and some common gotchas.\n",
    "\n",
    "When training your own model, you should search over these parameters to find the best settings for your particular dataset. You should use a held-out set of validation data for this step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYOaH9AhbCD_"
   },
   "source": [
    "| Parameter | Explanation |\n",
    "|-----------| ------------|\n",
    "| num_train_epochs | total number of training epochs (how many times to pass through the entire dataset; too much can cause overfitting) |\n",
    "| per_device_train_batch_size | batch size per device during training |\n",
    "| per_device_eval_batch_size |  batch size for evaluation |\n",
    "|  warmup_steps |  number of warmup steps for learning rate scheduler (set lower because of small dataset size) |\n",
    "| weight_decay | strength of weight decay (reduces size of weights, like regularization) |\n",
    "| output_dir | output directory for the fine-tuned model and configuration files |\n",
    "| logging_dir | directory for storing logs |\n",
    "| logging_steps | how often to print logging output (so that we can stop training early if the loss isn't going down) |\n",
    "| evaluation_strategy | evaluate while training so that we can see the accuracy going up |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "3idCswBVg6v_"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    num_train_epochs=4,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=16,   # batch size for evaluation\n",
    "    learning_rate=3e-5,              # initial learning rate for Adam optimizer\n",
    "    warmup_steps=100,                # number of warmup steps for learning rate scheduler (set lower because of small dataset size)\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    output_dir='./results',          # output directory\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=500,               # number of steps to output logging (set lower because of small dataset size)\n",
    "    evaluation_strategy='steps',     # evaluate during fine-tuning so that we can see progress\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Pb3xtidn-HJ"
   },
   "source": [
    "<br><br>\n",
    "\n",
    "## **Fine-tune the BERT model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_SN_oGLV8Vw"
   },
   "source": [
    "First, we define a custom evaluation function that returns the accuracy. You could modify this function to return precision, recall, F1, and/or other metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "pNIt7fcnqUCp"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "  labels = pred.label_ids\n",
    "  preds = pred.predictions.argmax(-1)\n",
    "  acc = accuracy_score(labels, preds)\n",
    "  return {\n",
    "      'accuracy': acc,\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g9xl5QLmWsAw"
   },
   "source": [
    "Then we create a HuggingFace `Trainer` object using the `TrainingArguments` object that we created above. We also send our `compute_metrics` function to the `Trainer` object, along with our test and train datasets.\n",
    "\n",
    "**Note:** This is what we've been aiming for this whole time! All the work of tokenizing, creating datasets, and setting the training arguments was for this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "fgc8FS50qV0_"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated ü§ó Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=test_dataset,           # evaluation dataset (usually a validation set; here we just send our test set)\n",
    "    compute_metrics=compute_metrics      # our custom evaluation function \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mo5QVLYjXGCN"
   },
   "source": [
    "Time to finally fine-tune! \n",
    "\n",
    "Be patient; if you've set everything in Colab to use GPUs, then it should only take a minute or two to run, but if you're running on CPU, it can take hours.\n",
    "\n",
    "After every 10 steps (as we specified in the TrainingArguments object), the trainer will output the current state of the model, including the training loss, validation (\"test\") loss, and accuracy (from our `compute_metrics` function).\n",
    "\n",
    "You should see the loss going down and the accuracy going up. If instead they are staying the same or oscillating, you probably need to change the fine-tuning parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "W64JwriVqcmk",
    "outputId": "52bc4785-ebf8-42c3-a4d1-187165ba12ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 18501\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4628\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4628' max='4628' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4628/4628 1:31:32, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.653600</td>\n",
       "      <td>0.507732</td>\n",
       "      <td>0.775273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.489200</td>\n",
       "      <td>0.415843</td>\n",
       "      <td>0.829939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.394800</td>\n",
       "      <td>0.406478</td>\n",
       "      <td>0.837212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.341100</td>\n",
       "      <td>0.378606</td>\n",
       "      <td>0.854424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.308700</td>\n",
       "      <td>0.387179</td>\n",
       "      <td>0.858909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.219600</td>\n",
       "      <td>0.410340</td>\n",
       "      <td>0.865697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.214100</td>\n",
       "      <td>0.425030</td>\n",
       "      <td>0.866909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.152800</td>\n",
       "      <td>0.480662</td>\n",
       "      <td>0.875152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.149300</td>\n",
       "      <td>0.487445</td>\n",
       "      <td>0.875030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 8250\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-500\n",
      "Configuration saved in ./results/checkpoint-500/config.json\n",
      "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8250\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-1000\n",
      "Configuration saved in ./results/checkpoint-1000/config.json\n",
      "Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8250\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-1500\n",
      "Configuration saved in ./results/checkpoint-1500/config.json\n",
      "Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8250\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-2000\n",
      "Configuration saved in ./results/checkpoint-2000/config.json\n",
      "Model weights saved in ./results/checkpoint-2000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8250\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-2500\n",
      "Configuration saved in ./results/checkpoint-2500/config.json\n",
      "Model weights saved in ./results/checkpoint-2500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8250\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-3000\n",
      "Configuration saved in ./results/checkpoint-3000/config.json\n",
      "Model weights saved in ./results/checkpoint-3000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8250\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-3500\n",
      "Configuration saved in ./results/checkpoint-3500/config.json\n",
      "Model weights saved in ./results/checkpoint-3500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8250\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-4000\n",
      "Configuration saved in ./results/checkpoint-4000/config.json\n",
      "Model weights saved in ./results/checkpoint-4000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 8250\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-4500\n",
      "Configuration saved in ./results/checkpoint-4500/config.json\n",
      "Model weights saved in ./results/checkpoint-4500/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4628, training_loss=0.3199310653046894, metrics={'train_runtime': 5493.9254, 'train_samples_per_second': 13.47, 'train_steps_per_second': 0.842, 'total_flos': 5993028236286504.0, 'train_loss': 0.3199310653046894, 'epoch': 4.0})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kXeIZ_LFqeps"
   },
   "source": [
    "<br><br>\n",
    "\n",
    "## **Save fine-tuned model**\n",
    "\n",
    "The following cell will save the model and its configuration files to a directory in Colab. To preserve this model for future use, you should download the model to your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kxkDWDfvqeAo",
    "outputId": "b1ce2595-ddb5-445a-8700-52ccacf3beb6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to Polarity_3\n",
      "Configuration saved in Polarity_3/config.json\n",
      "Model weights saved in Polarity_3/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(cached_model_directory_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epiLftYkZrzc"
   },
   "source": [
    "(Optional) If you've already fine-tuned and saved the model, you can reload it using the following line. You don't have to run fine-tuning every time you want to evaluate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JpzV4hFsLmZ6"
   },
   "source": [
    "<br><br>\n",
    "\n",
    "## **Evaluate fine-tuned model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-IvfhrBtYYcz"
   },
   "source": [
    "The following function of the `Trainer` object will run the built-in evaluation, including our `compute_metrics` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "id": "dshtTH0WLtM1",
    "outputId": "efbf37e9-da9d-4567-e2f3-cbc374438f1a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 8250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='516' max='516' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [516/516 02:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'epoch': 4.0,\n",
       " 'eval_accuracy': 0.875030303030303,\n",
       " 'eval_loss': 0.48702865839004517,\n",
       " 'eval_runtime': 133.838,\n",
       " 'eval_samples_per_second': 61.642,\n",
       " 'eval_steps_per_second': 3.855}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILJGLcCjYhPt"
   },
   "source": [
    "But we might want to do more fine-grained analysis of the model, so we extract the predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "v_E8oVjeLuv2",
    "outputId": "611471c3-2d15-4ffd-d92f-76f65d6e3817"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 8250\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1032' max='516' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [516/516 04:27]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_results = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WUYGfzczOuJE",
    "outputId": "fe94f5a5-a42f-4f87-8221-39994b943ebe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8250, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_results.predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "hqUTa5irLyN8"
   },
   "outputs": [],
   "source": [
    "predicted_labels = predicted_results.predictions.argmax(-1) # Get the highest probability prediction\n",
    "predicted_labels = predicted_labels.flatten().tolist()      # Flatten the predictions into a 1D list\n",
    "predicted_labels = [id2label[l] for l in predicted_labels]  # Convert from integers back to strings for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y2jtqnJbPMpu",
    "outputId": "2539ac90-2a23-4f88-fec9-576111e70044"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8250"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qVcMU45fLzli",
    "outputId": "c60aeb47-4a36-42cb-a5ab-6807cd58ca8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negativa       0.87      0.86      0.87      3617\n",
      "      Neutra       0.83      0.81      0.82       469\n",
      "    Positiva       0.88      0.89      0.89      4164\n",
      "\n",
      "    accuracy                           0.88      8250\n",
      "   macro avg       0.86      0.86      0.86      8250\n",
      "weighted avg       0.87      0.88      0.87      8250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, \n",
    "                            predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VmxEWmKYZf9a"
   },
   "outputs": [],
   "source": [
    "#l'evaluation sembra essere top\n",
    "#con 4 epoche √® meglio che con 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4J4pxn9NCC1_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2XtUaMCjCC2A"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "va8kkMblCC2A"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U-KOk7iACC2A"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S2B8gNceCC2B"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RZWrk5hwCC2B"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9v04bOpvCC2B"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RbPiEkNnCC2C"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7LtnqJbPCC2C"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D1IgcWghZgBt"
   },
   "outputs": [],
   "source": [
    "#RELOAD THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pMq9WKiQZgED",
    "outputId": "54582fdb-3d0d-4674-95d7-bd307f4ad704"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/28e5b750bf4f39cc620367720e105de1501cf36ec4ca7029eba82c1d2cc47caf.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n",
      "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/5cbdf121f196be5f1016cb102b197b0c34009e1e658f513515f2eebef9f38093.b33e51591f94f17c238ee9b1fac75b96ff2678cbaed6e108feadb3449d18dc24\n",
      "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/47087d99feeb3bc6184d7576ff089c52f7fbe3219fe48c6c4fa681e617753256.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/cf37a9dc282a679f121734d06f003625d14cfdaf55c14358c4c0b8e7e2b89ac9.7a727bd85e40715bec919a39cdd6f0aba27a8cd488f2d4e0f512448dcd02bf0f\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-multilingual-cased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading configuration file Polarity_3/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-multilingual-cased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file Polarity_3/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at Polarity_3.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "#tok = DistilBertTokenizerFast.from_pretrained(model_name) # The model_name needs to match our pre-trained model.\n",
    "tok = DistilBertTokenizerFast.from_pretrained(model_name) # The model_name needs to match our pre-trained model.\n",
    "mod = DistilBertForSequenceClassification.from_pretrained(cached_model_directory_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hr4Nawy9bSEo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JOBoAr-1s1qz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1sYLuCPPs1s-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CjzgjSTss1wX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M-VbtHWfBnt6"
   },
   "outputs": [],
   "source": [
    "#valutazione per domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f4zyL5pdLsDV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SJu8Kh4DBnt7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "iP_6qeODBnt7"
   },
   "outputs": [],
   "source": [
    "def prediction_test(dataset,modello):  #dataset fa riferimento al set di dati che vogliamo passare, modello dipende dal tipo di FT\n",
    "#poi ci sar√† anche la funzione per predire senza labels\n",
    "    tok = DistilBertTokenizerFast.from_pretrained('distilbert-base-multilingual-cased')\n",
    "    test_texts=dataset['Sentence']\n",
    "    test_labels=dataset['Polarity_Classification']\n",
    "\n",
    "#unique_labels = set(label for label in test_labels)\n",
    "#label2id = {label: id for id, label in enumerate(unique_labels)}\n",
    "#id2label = {id: label for label, id in label2id.items()}\n",
    "    unique_labels={'Neutra', 'Positiva', 'Negativa'}\n",
    "    label2id={'Negativa': 2, 'Neutra': 0, 'Positiva': 1}\n",
    "    id2label={2:'Negativa', 0:'Neutra', 1:'Positiva'}\n",
    "\n",
    "#train_encodings = tok(train_texts.tolist(), truncation=True, padding=True, max_length=max_length)\n",
    "    test_encodings  = tok(test_texts.tolist(), truncation=True, padding=True, max_length=max_length)\n",
    "\n",
    "#train_labels_encoded = [label2id[y] for y in train_labels.tolist()]\n",
    "    test_labels_encoded  = [label2id[y] for y in test_labels.tolist()]\n",
    "    \n",
    "\n",
    "    class MyDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, encodings, labels):\n",
    "            self.encodings = encodings\n",
    "            self.labels = labels\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "            item['labels'] = torch.tensor(self.labels[idx])\n",
    "            return item\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.labels)\n",
    "\n",
    "#train_dataset = MyDataset(train_encodings, train_labels_encoded)\n",
    "    test_dataset = MyDataset(test_encodings, test_labels_encoded)\n",
    "    \n",
    "    trainer = Trainer(model=modello)  #basta avere il modello come parametro\n",
    "\n",
    "    predicted_results=trainer.predict(test_dataset)\n",
    "    \n",
    "    predicted_labels = predicted_results.predictions.argmax(-1) # Get the highest probability prediction\n",
    "    predicted_labels = predicted_labels.flatten().tolist()      # Flatten the predictions into a 1D list\n",
    "    predicted_labels = [id2label[l] for l in predicted_labels]  # Convert from integers back to strings for readability\n",
    "\n",
    "#len(predicted_labels)\n",
    "\n",
    "    return print(classification_report(test_labels,predicted_labels)),predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rwfx6FzVBnt7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IYvmLw_yBnt7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-M2_uEozBnt8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PZn--Ex4Bnt8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "20F56JNrs62D"
   },
   "outputs": [],
   "source": [
    "#RELOAD THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wVFVfy0ws62D",
    "outputId": "7464549f-0278-4b08-b91d-f1a2b7433e9b"
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "#tok = DistilBertTokenizerFast.from_pretrained(model_name) # The model_name needs to match our pre-trained model.\n",
    "tok = DistilBertTokenizerFast.from_pretrained(model_name) # The model_name needs to match our pre-trained model.\n",
    "mod = DistilBertForSequenceClassification.from_pretrained(cached_model_directory_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4BDtPZubs62F"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iyB3NCl4q8oP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 873
    },
    "id": "oGv2FlCebeMz",
    "outputId": "eccd3bc9-0cda-4849-a567-b540dfc27379"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/28e5b750bf4f39cc620367720e105de1501cf36ec4ca7029eba82c1d2cc47caf.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n",
      "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/5cbdf121f196be5f1016cb102b197b0c34009e1e658f513515f2eebef9f38093.b33e51591f94f17c238ee9b1fac75b96ff2678cbaed6e108feadb3449d18dc24\n",
      "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/47087d99feeb3bc6184d7576ff089c52f7fbe3219fe48c6c4fa681e617753256.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/cf37a9dc282a679f121734d06f003625d14cfdaf55c14358c4c0b8e7e2b89ac9.7a727bd85e40715bec919a39cdd6f0aba27a8cd488f2d4e0f512448dcd02bf0f\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-multilingual-cased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 615\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negativa       0.77      0.70      0.73        98\n",
      "      Neutra       0.86      0.88      0.87       274\n",
      "    Positiva       0.89      0.90      0.89       243\n",
      "\n",
      "    accuracy                           0.86       615\n",
      "   macro avg       0.84      0.83      0.83       615\n",
      "weighted avg       0.86      0.86      0.86       615\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction_test(test[:615],mod)   #tabella per inglesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V2RZv-Y0beM1"
   },
   "outputs": [],
   "source": [
    "#per le inglesi e quindi domain book, l'accuracy e le altre statistiche per neutre e positive sono ottime\n",
    "#per le negative le statistiche sono sufficientemente buone, anche per il fatto che il campione √® piccolo\n",
    "\n",
    "#risultati migliori rispetto a strategia 1 di training (soloEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eQevi6vrbeM2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jowBlG9AVeI2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vv2Ml8fJVeK2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 873
    },
    "id": "zf7Gm3CTVeM-",
    "outputId": "f39efde4-d1c4-440e-ce38-acec2badb4ca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/vocab.txt from cache at C:\\Users\\Fossati/.cache\\huggingface\\transformers\\28e5b750bf4f39cc620367720e105de1501cf36ec4ca7029eba82c1d2cc47caf.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n",
      "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/tokenizer.json from cache at C:\\Users\\Fossati/.cache\\huggingface\\transformers\\5cbdf121f196be5f1016cb102b197b0c34009e1e658f513515f2eebef9f38093.b33e51591f94f17c238ee9b1fac75b96ff2678cbaed6e108feadb3449d18dc24\n",
      "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at C:\\Users\\Fossati/.cache\\huggingface\\transformers\\47087d99feeb3bc6184d7576ff089c52f7fbe3219fe48c6c4fa681e617753256.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/config.json from cache at C:\\Users\\Fossati/.cache\\huggingface\\transformers\\cf37a9dc282a679f121734d06f003625d14cfdaf55c14358c4c0b8e7e2b89ac9.7a727bd85e40715bec919a39cdd6f0aba27a8cd488f2d4e0f512448dcd02bf0f\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-multilingual-cased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 3635\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='455' max='455' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [455/455 06:39]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negativa       0.94      0.95      0.95      1517\n",
      "      Neutra       0.78      0.73      0.75       195\n",
      "    Positiva       0.97      0.96      0.96      1923\n",
      "\n",
      "    accuracy                           0.95      3635\n",
      "   macro avg       0.89      0.88      0.89      3635\n",
      "weighted avg       0.95      0.95      0.95      3635\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " ['Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Neutra',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Neutra',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Neutra',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Neutra',\n",
       "  'Negativa',\n",
       "  'Neutra',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Neutra',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Neutra',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Neutra',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Neutra',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Neutra',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Neutra',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Neutra',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Neutra',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Neutra',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Neutra',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Neutra',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Neutra',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Neutra',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Neutra',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Neutra',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Neutra',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Neutra',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Neutra',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Neutra',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Neutra',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Neutra',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Neutra',\n",
       "  'Negativa',\n",
       "  'Neutra',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Neutra',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Neutra',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Neutra',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Neutra',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Neutra',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Neutra',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Neutra',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  ...])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_test(test[615:4250],mod)   #tabella per italiane, domain social media e hotel reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gKkmz6tqVeWb"
   },
   "outputs": [],
   "source": [
    "#risultati top per italia. Le neutre pi√π che sufficientemente buone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dKlsoP9KbeM4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aZzWu78Nq82e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2yMRdNk3V4aA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 977
    },
    "id": "IWLdyt_bV4cL",
    "outputId": "59d38193-461b-4966-ac0d-cf8ad31d095c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/vocab.txt from cache at C:\\Users\\Fossati/.cache\\huggingface\\transformers\\28e5b750bf4f39cc620367720e105de1501cf36ec4ca7029eba82c1d2cc47caf.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n",
      "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/tokenizer.json from cache at C:\\Users\\Fossati/.cache\\huggingface\\transformers\\5cbdf121f196be5f1016cb102b197b0c34009e1e658f513515f2eebef9f38093.b33e51591f94f17c238ee9b1fac75b96ff2678cbaed6e108feadb3449d18dc24\n",
      "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at C:\\Users\\Fossati/.cache\\huggingface\\transformers\\47087d99feeb3bc6184d7576ff089c52f7fbe3219fe48c6c4fa681e617753256.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/config.json from cache at C:\\Users\\Fossati/.cache\\huggingface\\transformers\\cf37a9dc282a679f121734d06f003625d14cfdaf55c14358c4c0b8e7e2b89ac9.7a727bd85e40715bec919a39cdd6f0aba27a8cd488f2d4e0f512448dcd02bf0f\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-multilingual-cased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 4000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 03:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negativa       0.82      0.80      0.81      2002\n",
      "      Neutra       0.00      0.00      0.00         0\n",
      "    Positiva       0.81      0.83      0.82      1998\n",
      "\n",
      "    accuracy                           0.81      4000\n",
      "   macro avg       0.54      0.54      0.54      4000\n",
      "weighted avg       0.81      0.81      0.81      4000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fossati\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Fossati\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Fossati\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " ['Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Negativa',\n",
       "  'Neutra',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Positiva',\n",
       "  'Negativa',\n",
       "  'Positiva',\n",
       "  ...])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ko_pred=prediction_test(test[4250:],mod)   #tabella per koreane, domain movie reviews\n",
    "ko_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "je4Y1-z9V4iX"
   },
   "outputs": [],
   "source": [
    "#il modello √® ottimo anche per coreano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wbKbvos_XXAL"
   },
   "outputs": [],
   "source": [
    "#questa strategia sembra essere ottima \n",
    "#non si aggiunge affatto del rumore nel modello inserendo dati di altri domain. Prevale il training sulla lingua stando a questi esperimenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "88xVgdxwq8sI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#capire quante vengono classificate come neutre: potrebbe essere errore di classificazione oppure ZSCLT del modello bert\n",
    "#meno sono meglio √® ad ogni modo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neu=0\n",
    "for clas in ko_pred[1]:\n",
    "    if clas == 'Neutra':\n",
    "        neu+=1\n",
    "neu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ko_pred[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 su 4000 vengono classificate come neutre, sono ovviamente sbagliate ma ottimo risultato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QTfGMhCGq8um"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AbM4ckOYq8xQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3uAV8AM7q8zg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FineTuning_Polarity3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "042cc51b95ed459cb55708ad348cdffe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_47c17838fbd14e548875e6353ef7bac6",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_c9aef65bcc4248beb37db33c9b8d72c2",
      "value": "Downloading: 100%"
     }
    },
    "0a8eb73c68d64512833319bf638b21fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_36cfcac443294355aff5aea1dc1e82a2",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_6116d2245f0b4c45899cf80f8a741891",
      "value": " 466/466 [00:00&lt;00:00, 12.1kB/s]"
     }
    },
    "0cdfee14eb504f5f9f31cc2adb6aa7ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "16b6a7526a454896ae8e747d8c69d40d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "16f5b986cad6491c8b5fa08d9b4e98cd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1fc10461908a410c98c17cc31bdc2f58": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21c73885b0c548da9141a8d7f1e86b1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_affbbba6f0a74e68b4f6f3e7e30cf425",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_d3c16ea0f0bc40318a07d71301df490b",
      "value": " 517M/517M [00:45&lt;00:00, 28.6MB/s]"
     }
    },
    "21e3089bb9ab4f94aaa415fcefa2c7e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2aa7cea2f2ce490cafdfa020518476d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_43ca0fa1e42c4be89f1a9018e8ad1c88",
      "max": 541808922,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b64c9fb4b04a45cf80c9459a1303e32b",
      "value": 541808922
     }
    },
    "2bd7687d5f614c87a73047d271c57f81": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "36cfcac443294355aff5aea1dc1e82a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "428fc073b24048f8a172d4e3ac904528": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4358b7c34dd94d88813065447b0e3d3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fb0fdc1432a44416a5aa1f2f9f0963be",
       "IPY_MODEL_a679d4cf3072407fa42bf4f53e4b193b",
       "IPY_MODEL_845df591a09a49bebc5d032328816223"
      ],
      "layout": "IPY_MODEL_912097536125434c88e43a15fbb0568c"
     }
    },
    "43ca0fa1e42c4be89f1a9018e8ad1c88": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "472714479e9c4e8587e5d1799ab8e463": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47c17838fbd14e548875e6353ef7bac6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e9d577ac7f244c39acd1146bfb9d0ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "51d13f8f59c84ea5b678eab69458ccbf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6116d2245f0b4c45899cf80f8a741891": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "62365c5fe15c42f39e8f8a8ab32d8384": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "66bb7c0d8c7d412b8f3c4bbb11f51dc3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a9fab4494e346749cffa129cc804c2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7feade48a94843efaa49814a0ce7efcb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "838723b7b46e46bfaf9acf1998017114": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "845df591a09a49bebc5d032328816223": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e02abb54586a42d381a105558b3a693e",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_9621c21eae2541569bdd5a212aa610e1",
      "value": " 1.87M/1.87M [00:00&lt;00:00, 1.74MB/s]"
     }
    },
    "8469d4a936a4412685ce08350ed517d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_51d13f8f59c84ea5b678eab69458ccbf",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_9b894ceb2a93460ebdcc65682e00cea1",
      "value": " 972k/972k [00:00&lt;00:00, 1.32MB/s]"
     }
    },
    "84b1165e342c4dcab8a16955c51c9e04": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87bbbf8803114dfcafcce89958d01ca8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "912097536125434c88e43a15fbb0568c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9621c21eae2541569bdd5a212aa610e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9b357745818e4db59fa6b6fe5fbe3069": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1fc10461908a410c98c17cc31bdc2f58",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_62365c5fe15c42f39e8f8a8ab32d8384",
      "value": " 29.0/29.0 [00:00&lt;00:00, 541B/s]"
     }
    },
    "9b894ceb2a93460ebdcc65682e00cea1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a3159f042f4d4798a5f82b1a5175c0dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ca486e16524d4547960ab7841f810164",
       "IPY_MODEL_b1e7939eb1ea484a9e393b93abc83905",
       "IPY_MODEL_0a8eb73c68d64512833319bf638b21fb"
      ],
      "layout": "IPY_MODEL_2bd7687d5f614c87a73047d271c57f81"
     }
    },
    "a679d4cf3072407fa42bf4f53e4b193b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_66bb7c0d8c7d412b8f3c4bbb11f51dc3",
      "max": 1961828,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f88f3486e31d43f8a9ba81a2ef345f01",
      "value": 1961828
     }
    },
    "aa1c1d05c6774ca5a34ec4471f9e8d19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d7df69d3039e40ed8c7a28007567a74b",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_87bbbf8803114dfcafcce89958d01ca8",
      "value": "Downloading: 100%"
     }
    },
    "affbbba6f0a74e68b4f6f3e7e30cf425": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b1e7939eb1ea484a9e393b93abc83905": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_472714479e9c4e8587e5d1799ab8e463",
      "max": 466,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_16b6a7526a454896ae8e747d8c69d40d",
      "value": 466
     }
    },
    "b2d62e9094824163b99554f768975c4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e501e57fc2194e27a0dfc3094d8cd0f1",
       "IPY_MODEL_fedf6d6698ce4ce8b77f2cc24013dc5a",
       "IPY_MODEL_9b357745818e4db59fa6b6fe5fbe3069"
      ],
      "layout": "IPY_MODEL_e2c27467ea0c462f8a35bd756d0928df"
     }
    },
    "b64c9fb4b04a45cf80c9459a1303e32b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c7233912eb52420c903e7f6313839fb1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9aef65bcc4248beb37db33c9b8d72c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ca486e16524d4547960ab7841f810164": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c7233912eb52420c903e7f6313839fb1",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_6a9fab4494e346749cffa129cc804c2f",
      "value": "Downloading: 100%"
     }
    },
    "d3c16ea0f0bc40318a07d71301df490b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d7df69d3039e40ed8c7a28007567a74b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dda42200f55a410eab281a0e6d4ad866": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ddabf3a6ed5d4069b435a315fc71878b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_84b1165e342c4dcab8a16955c51c9e04",
      "max": 995526,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4e9d577ac7f244c39acd1146bfb9d0ce",
      "value": 995526
     }
    },
    "df013c2043a14cdebd80aa2f91db14be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e00864cc625d4caa800153e937725da7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_042cc51b95ed459cb55708ad348cdffe",
       "IPY_MODEL_2aa7cea2f2ce490cafdfa020518476d7",
       "IPY_MODEL_21c73885b0c548da9141a8d7f1e86b1d"
      ],
      "layout": "IPY_MODEL_0cdfee14eb504f5f9f31cc2adb6aa7ae"
     }
    },
    "e02abb54586a42d381a105558b3a693e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2c27467ea0c462f8a35bd756d0928df": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e434b5890bc048318041b62b3878566b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_aa1c1d05c6774ca5a34ec4471f9e8d19",
       "IPY_MODEL_ddabf3a6ed5d4069b435a315fc71878b",
       "IPY_MODEL_8469d4a936a4412685ce08350ed517d3"
      ],
      "layout": "IPY_MODEL_7feade48a94843efaa49814a0ce7efcb"
     }
    },
    "e501e57fc2194e27a0dfc3094d8cd0f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dda42200f55a410eab281a0e6d4ad866",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_df013c2043a14cdebd80aa2f91db14be",
      "value": "Downloading: 100%"
     }
    },
    "f88f3486e31d43f8a9ba81a2ef345f01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fb0fdc1432a44416a5aa1f2f9f0963be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_428fc073b24048f8a172d4e3ac904528",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_21e3089bb9ab4f94aaa415fcefa2c7e9",
      "value": "Downloading: 100%"
     }
    },
    "fedf6d6698ce4ce8b77f2cc24013dc5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_16f5b986cad6491c8b5fa08d9b4e98cd",
      "max": 29,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_838723b7b46e46bfaf9acf1998017114",
      "value": 29
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
