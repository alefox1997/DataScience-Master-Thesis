{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "513122c5",
   "metadata": {},
   "source": [
    "# EVALUATION EMOTION DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "13989acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset sem_eval2018_task1 (C:\\Users\\Fossati\\.cache\\huggingface\\datasets\\sem_eval2018_task1\\subtask5.english\\1.1.0\\c8af6e4accd23f95ac75d14477b0678a4f59d5da34e480ad7de8112ffab04a3d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24c0f50290ff415cbb0e5f6e5601d3d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ID', 'Tweet', 'anger', 'anticipation', 'disgust', 'fear', 'joy', 'love', 'optimism', 'pessimism', 'sadness', 'surprise', 'trust'],\n",
       "        num_rows: 6838\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['ID', 'Tweet', 'anger', 'anticipation', 'disgust', 'fear', 'joy', 'love', 'optimism', 'pessimism', 'sadness', 'surprise', 'trust'],\n",
       "        num_rows: 3259\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['ID', 'Tweet', 'anger', 'anticipation', 'disgust', 'fear', 'joy', 'love', 'optimism', 'pessimism', 'sadness', 'surprise', 'trust'],\n",
       "        num_rows: 886\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"sem_eval_2018_task_1\", 'subtask5.english')\n",
    "dataset\n",
    "#https://huggingface.co/datasets/sem_eval_2018_task_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "26cf3e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Anger</th>\n",
       "      <th>Surprise</th>\n",
       "      <th>Fear</th>\n",
       "      <th>Joy</th>\n",
       "      <th>Sadness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“Worry is a down payment on a problem you may ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Whatever you decide to do make sure it makes y...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Max_Kellerman  it also helps that the majorit...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Accept the challenges so that you can literall...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My roommate: it's okay that we can't spell bec...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6833</th>\n",
       "      <td>@nicky57672 Hi! We are working towards your hi...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6834</th>\n",
       "      <td>@andreamitchell said @berniesanders not only d...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6835</th>\n",
       "      <td>@isthataspider @dhodgs i will fight this guy! ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6836</th>\n",
       "      <td>i wonder how a guy can broke his penis while h...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6837</th>\n",
       "      <td>I'm highly animated even though I'm decomposing.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6838 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence  Anger  Surprise  \\\n",
       "0     “Worry is a down payment on a problem you may ...  False     False   \n",
       "1     Whatever you decide to do make sure it makes y...  False     False   \n",
       "2     @Max_Kellerman  it also helps that the majorit...   True     False   \n",
       "3     Accept the challenges so that you can literall...  False     False   \n",
       "4     My roommate: it's okay that we can't spell bec...   True     False   \n",
       "...                                                 ...    ...       ...   \n",
       "6833  @nicky57672 Hi! We are working towards your hi...  False     False   \n",
       "6834  @andreamitchell said @berniesanders not only d...  False      True   \n",
       "6835  @isthataspider @dhodgs i will fight this guy! ...   True     False   \n",
       "6836  i wonder how a guy can broke his penis while h...  False      True   \n",
       "6837   I'm highly animated even though I'm decomposing.  False     False   \n",
       "\n",
       "       Fear    Joy  Sadness  \n",
       "0     False  False    False  \n",
       "1     False   True    False  \n",
       "2     False   True    False  \n",
       "3     False   True    False  \n",
       "4     False  False    False  \n",
       "...     ...    ...      ...  \n",
       "6833  False  False    False  \n",
       "6834  False  False    False  \n",
       "6835  False  False    False  \n",
       "6836  False  False    False  \n",
       "6837  False  False    False  \n",
       "\n",
       "[6838 rows x 6 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sem_eval_train=pd.DataFrame(list(zip(dataset['train']['Tweet'],dataset['train']['anger'],dataset['train']['surprise'],dataset['train']['fear'],dataset['train']['joy'],dataset['train']['sadness'])), columns=['Sentence','Anger','Surprise','Fear','Joy','Sadness'])\n",
    "sem_eval_train\n",
    "\n",
    "#sfruttiamo il dataset di train per la evaluatione dal momento che il test ha problemi nell'importazione con la libreria\n",
    "#non cambia nulla, anzi, abbiamo + dati, quindi anche meglio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbf9fda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cc7e09e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“Worry is a down payment on a problem you may ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Whatever you decide to do make sure it makes y...</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Max_Kellerman  it also helps that the majorit...</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Accept the challenges so that you can literall...</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My roommate: it's okay that we can't spell bec...</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6833</th>\n",
       "      <td>@nicky57672 Hi! We are working towards your hi...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6834</th>\n",
       "      <td>@andreamitchell said @berniesanders not only d...</td>\n",
       "      <td>Surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6835</th>\n",
       "      <td>@isthataspider @dhodgs i will fight this guy! ...</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6836</th>\n",
       "      <td>i wonder how a guy can broke his penis while h...</td>\n",
       "      <td>Surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6837</th>\n",
       "      <td>I'm highly animated even though I'm decomposing.</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6838 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence  Emotions\n",
       "0     “Worry is a down payment on a problem you may ...   Neutral\n",
       "1     Whatever you decide to do make sure it makes y...       Joy\n",
       "2     @Max_Kellerman  it also helps that the majorit...       Joy\n",
       "3     Accept the challenges so that you can literall...       Joy\n",
       "4     My roommate: it's okay that we can't spell bec...     Anger\n",
       "...                                                 ...       ...\n",
       "6833  @nicky57672 Hi! We are working towards your hi...   Neutral\n",
       "6834  @andreamitchell said @berniesanders not only d...  Surprise\n",
       "6835  @isthataspider @dhodgs i will fight this guy! ...     Anger\n",
       "6836  i wonder how a guy can broke his penis while h...  Surprise\n",
       "6837   I'm highly animated even though I'm decomposing.   Neutral\n",
       "\n",
       "[6838 rows x 2 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#questo dataset è per multi label classification, per cui dobbiamo rimaneggiarlo, scegliendo una delle emozioni annotate in ogni frase\n",
    "#cerchiamo di equilibrare il dataset\n",
    "emo_class=[]\n",
    "for index,row in sem_eval_train.iterrows():\n",
    "\n",
    "    if str(row['Surprise']) == 'True':\n",
    "        emo_class.append('Surprise')\n",
    "    elif str(row['Fear']) == 'True':\n",
    "        emo_class.append('Fear')\n",
    "    elif str(row['Sadness']) == 'True':\n",
    "        emo_class.append('Sadness')\n",
    "    elif str(row['Joy']) == 'True':\n",
    "        emo_class.append('Joy')\n",
    "    elif str(row['Anger']) == 'True':\n",
    "        emo_class.append('Anger')\n",
    "    else:\n",
    "        emo_class.append('Neutral')\n",
    "        \n",
    "sem_eval_test=pd.DataFrame(list(zip(sem_eval_train['Sentence'],emo_class)), columns=['Sentence','Emotions'])\n",
    "sem_eval_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "82aa48a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Emotions\n",
       "Anger       1195\n",
       "Fear        1184\n",
       "Joy         1977\n",
       "Neutral      612\n",
       "Sadness     1509\n",
       "Surprise     361\n",
       "dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sem_eval_test.groupby('Emotions').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "586ccb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#questo test tuttavia non è troppo affidabile per i motivi antiicpati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee123e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6d377f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57d47e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9690e15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e8e88f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988dd1af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad11539",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6143eef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab796c33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b3d395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80daa74a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f186a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6b3600",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweet eval\n",
    "\n",
    "\n",
    "#https://github.com/cardiffnlp/tweeteval/blob/main/datasets/emotion/mapping.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "22f5ae2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#Deppression is real. Partners w/ #depressed p...</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user Interesting choice of words... Are you c...</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My visit to hospital for care triggered #traum...</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@user Welcome to #MPSVT! We are delighted to h...</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What makes you feel #joyful?</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>I need a sparkling bodysuit . No occasion. Jus...</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>@user I've finished reading it; simply mind-bl...</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>shaft abrasions from panties merely shifted to...</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>All this fake outrage. Y'all need to stop 🤣</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>Would be ever so grateful if you could record ...</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1298 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence Emotions\n",
       "0     #Deppression is real. Partners w/ #depressed p...  Sadness\n",
       "1     @user Interesting choice of words... Are you c...    Anger\n",
       "2     My visit to hospital for care triggered #traum...  Sadness\n",
       "3     @user Welcome to #MPSVT! We are delighted to h...      Joy\n",
       "4                         What makes you feel #joyful?       Joy\n",
       "...                                                 ...      ...\n",
       "1293  I need a sparkling bodysuit . No occasion. Jus...      Joy\n",
       "1294  @user I've finished reading it; simply mind-bl...  Sadness\n",
       "1295  shaft abrasions from panties merely shifted to...    Anger\n",
       "1296       All this fake outrage. Y'all need to stop 🤣     Anger\n",
       "1297  Would be ever so grateful if you could record ...      Joy\n",
       "\n",
       "[1298 rows x 2 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets=pd.read_csv(\"C:\\\\Users\\\\Fossati\\\\Desktop\\\\Tesi\\\\Dati\\\\Dati_FineTuningBERT\\\\Train_Test_emotion\\\\Evaluation_Data_emo\\\\tweets.txt\",sep=\"\\n\",header=None)[0].tolist()\n",
    "labels=pd.read_csv(\"C:\\\\Users\\\\Fossati\\\\Desktop\\\\Tesi\\\\Dati\\\\Dati_FineTuningBERT\\\\Train_Test_emotion\\\\Evaluation_Data_emo\\\\labels.txt\",sep=\"\\n\",header=None)[0].tolist()\n",
    "tweeteval=pd.DataFrame(list(zip(tweets, labels)),columns=['Sentence','Emotions'])\n",
    "to_drop=[]\n",
    "emo=[]\n",
    "for index, row in tweeteval.iterrows():\n",
    "    if int(row['Emotions']) == 0:\n",
    "        emo.append('Anger')\n",
    "    elif int(row['Emotions']) == 1:\n",
    "        emo.append('Joy')\n",
    "    elif int(row['Emotions']) == 3:\n",
    "        emo.append('Sadness')\n",
    "    else:\n",
    "        emo.append('drop')\n",
    "        to_drop.append(index)\n",
    "tweeteval['Emotions']=emo\n",
    "tweeteval=tweeteval.drop(to_drop,axis=0 ).reset_index()\n",
    "tweeteval=tweeteval.drop('index',axis=1)\n",
    "tweeteval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c2c8c818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Emotions\n",
       "Anger      558\n",
       "Joy        358\n",
       "Sadness    382\n",
       "dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweeteval.groupby('Emotions').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9818776",
   "metadata": {},
   "outputs": [],
   "source": [
    "#qui abbiamo la valutazione solo su la metà delle emozioni, tuttavia è più adatto al nostro scopo rispetto al primo dataset\n",
    "#che viene creato per effettuare evalutation multiclass. Noi invece vogliamo predire per ogni frase una sola emozione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61ea273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc789ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495b6499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120cd370",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba685c57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048052df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#proviamo ad effettuare l'evaluation con alcuni modelli vincitori degli step precedenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b606eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a3a0b27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import XLMRobertaTokenizerFast, XLMRobertaForSequenceClassification \n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d653edac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7f66afda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_test(dataset, modello, tok):  #dataset fa riferimento al set di dati che vogliamo passare, modello dipende dal tipo di FT\n",
    "#poi ci sarà anche la funzione per predire senza labels\n",
    "\n",
    "    test_texts=dataset['Sentence']\n",
    "    test_labels=dataset['Emotions']\n",
    "\n",
    "    #unique_labels = set(label for label in test_labels)\n",
    "    #label2id = {label: id for id, label in enumerate(unique_labels)}\n",
    "    #id2label = {id: label for label, id in label2id.items()}\n",
    "    unique_labels={'Sadness', 'Surprise', 'Joy', 'Neutral', 'Anger','Fear'}\n",
    "    label2id={'Sadness':0, 'Surprise':1, 'Joy':2, 'Neutral':3, 'Anger':4, 'Fear':5}\n",
    "    id2label={ 0:'Sadness', 1:'Surprise', 2:'Joy', 3:'Neutral', 4:'Anger', 5:'Fear'}  \n",
    "\n",
    "#train_encodings = tok(train_texts.tolist(), truncation=True, padding=True, max_length=max_length)\n",
    "    test_encodings  = tok(test_texts.tolist(), truncation=True, padding=True, max_length=128)\n",
    "\n",
    "#train_labels_encoded = [label2id[y] for y in train_labels.tolist()]\n",
    "    test_labels_encoded  = [label2id[y] for y in test_labels.tolist()]\n",
    "    \n",
    "\n",
    "    class MyDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, encodings, labels):\n",
    "            self.encodings = encodings\n",
    "            self.labels = labels\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "            item['labels'] = torch.tensor(self.labels[idx])\n",
    "            return item\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.labels)\n",
    "\n",
    "#train_dataset = MyDataset(train_encodings, train_labels_encoded)\n",
    "    test_dataset = MyDataset(test_encodings, test_labels_encoded)\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "    num_train_epochs=4,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=16,   # batch size for evaluation\n",
    "    learning_rate=2e-5,              # initial learning rate for Adam optimizer\n",
    "    warmup_steps=100,                # number of warmup steps for learning rate scheduler (set lower because of small dataset size)\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    output_dir='./results',          # output directory\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=1500,               # number of steps to output logging (set lower because of small dataset size)\n",
    "    evaluation_strategy='steps'     # evaluate during fine-tuning so that we can see progress\n",
    ")\n",
    "    \n",
    "    trainer = Trainer(model=modello, args=training_args)  #basta avere il modello come parametro\n",
    "\n",
    "    predicted_results=trainer.predict(test_dataset)\n",
    "    \n",
    "    predicted_labels = predicted_results.predictions.argmax(-1) # Get the highest probability prediction\n",
    "    predicted_labels = predicted_labels.flatten().tolist()      # Flatten the predictions into a 1D list\n",
    "    predicted_labels = [id2label[l] for l in predicted_labels]  # Convert from integers back to strings for readability\n",
    "\n",
    "#len(predicted_labels)\n",
    "\n",
    "    return print(classification_report(test_labels,predicted_labels)), print(confusion_matrix(test_labels,predicted_labels,labels=['Sadness', 'Surprise', 'Joy', 'Neutral', 'Anger','Fear']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17518fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c89a19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5a5021d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#questa seconda funzione aiita il modello nella classificazione, escludendo dalla scelta le classi che non ci sono nel training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a1fc6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a8cd8f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_test_whelp(dataset, modello, tok):  #dataset fa riferimento al set di dati che vogliamo passare, modello dipende dal tipo di FT\n",
    "\n",
    "    test_texts=dataset['Sentence']\n",
    "    test_labels=dataset['Emotions']\n",
    "\n",
    "    #unique_labels = set(label for label in test_labels)\n",
    "    #label2id = {label: id for id, label in enumerate(unique_labels)}\n",
    "    #id2label = {id: label for label, id in label2id.items()}\n",
    "    unique_labels={'Sadness', 'Surprise', 'Joy', 'Neutral', 'Anger','Fear'}\n",
    "    label2id={'Sadness':0, 'Surprise':1, 'Joy':2, 'Neutral':3, 'Anger':4, 'Fear':5}\n",
    "    id2label={ 0:'Sadness', 1:'Surprise', 2:'Joy', 3:'Neutral', 4:'Anger', 5:'Fear'}  \n",
    "\n",
    "#train_encodings = tok(train_texts.tolist(), truncation=True, padding=True, max_length=max_length)\n",
    "    test_encodings  = tok(test_texts.tolist(), truncation=True, padding=True, max_length=128)\n",
    "\n",
    "#train_labels_encoded = [label2id[y] for y in train_labels.tolist()]\n",
    "    test_labels_encoded  = [label2id[y] for y in test_labels.tolist()]\n",
    "    \n",
    "\n",
    "    class MyDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, encodings, labels):\n",
    "            self.encodings = encodings\n",
    "            self.labels = labels\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "            item['labels'] = torch.tensor(self.labels[idx])\n",
    "            return item\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.labels)\n",
    "\n",
    "#train_dataset = MyDataset(train_encodings, train_labels_encoded)\n",
    "    test_dataset = MyDataset(test_encodings, test_labels_encoded)\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "    num_train_epochs=4,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=16,   # batch size for evaluation\n",
    "    learning_rate=2e-5,              # initial learning rate for Adam optimizer\n",
    "    warmup_steps=100,                # number of warmup steps for learning rate scheduler (set lower because of small dataset size)\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    output_dir='./results',          # output directory\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=1500,               # number of steps to output logging (set lower because of small dataset size)\n",
    "    evaluation_strategy='steps'     # evaluate during fine-tuning so that we can see progress\n",
    ")\n",
    "    \n",
    "    trainer = Trainer(model=modello, args=training_args)  #basta avere il modello come parametro\n",
    "\n",
    "    pr=trainer.predict(test_dataset)\n",
    "    \n",
    "\n",
    "    \n",
    "    count=0\n",
    "    predicted_labels=[]\n",
    "    for el in pr[0]:\n",
    "        pred=np.argmax([pr[0][count][0],pr[0][count][2],pr[0][count][4]])\n",
    "        if int(pred) == 0:\n",
    "            predicted_labels.append(0)\n",
    "        elif int(pred) == 1:\n",
    "            predicted_labels.append(2)\n",
    "        else:\n",
    "            predicted_labels.append(4)\n",
    "        count+=1 \n",
    "        \n",
    "    predicted_labels2 = [id2label[l] for l in predicted_labels]  # Convert from integers back to strings for readability\n",
    "\n",
    "#len(predicted_labels)\n",
    "\n",
    "    return print(classification_report(test_labels,predicted_labels2)), print(confusion_matrix(test_labels,predicted_labels2,labels=['Sadness' ,'Joy', 'Anger']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38510fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73039770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1698dbe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "428f1d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_test_baseline(dataset, modello, tok, whichdata):  #dataset fa riferimento al set di dati che vogliamo passare, modello dipende dal tipo di FT\n",
    "#poi ci sarà anche la funzione per predire senza labels\n",
    "    #modello = XLMRobertaForSequenceClassification.from_pretrained('xlm-roberta-base')\n",
    "    #tok = XLMRobertaTokenizerFast.from_pretrained('xlm-roberta-base')\n",
    "    test_texts=dataset['Sentence']\n",
    "    test_labels=dataset['Emotions']\n",
    "\n",
    "    if whichdata == 1: #1 per semeval\n",
    "        unique_labels={'Sadness', 'Surprise', 'Joy', 'Neutral', 'Anger','Fear'}\n",
    "        label2id={'Sadness':0, 'Surprise':1, 'Joy':2, 'Neutral':3, 'Anger':4, 'Fear':5}\n",
    "        id2label={ 0:'Sadness', 1:'Surprise', 2:'Joy', 3:'Neutral', 4:'Anger', 5:'Fear'}\n",
    "        \n",
    "        lista_labels=['Sadness', 'Surprise', 'Joy', 'Neutral', 'Anger','Fear']\n",
    "    \n",
    "    elif whichdata == 2: #2 per tweeteval\n",
    "        \n",
    "        unique_labels={'Sadness', 'Joy', 'Anger'}\n",
    "        label2id={'Sadness':0,  'Joy':1,  'Anger':2}\n",
    "        id2label={ 0:'Sadness',  1:'Joy', 2:'Anger'}\n",
    "        \n",
    "        lista_labels=['Sadness', 'Joy', 'Anger']        \n",
    "\n",
    "#train_encodings = tok(train_texts.tolist(), truncation=True, padding=True, max_length=max_length)\n",
    "    test_encodings  = tok(test_texts.tolist(), truncation=True, padding=True, max_length=128)\n",
    "\n",
    "#train_labels_encoded = [label2id[y] for y in train_labels.tolist()]\n",
    "    test_labels_encoded  = [label2id[y] for y in test_labels.tolist()]\n",
    "    \n",
    "\n",
    "    class MyDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, encodings, labels):\n",
    "            self.encodings = encodings\n",
    "            self.labels = labels\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "            item['labels'] = torch.tensor(self.labels[idx])\n",
    "            return item\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.labels)\n",
    "\n",
    "#train_dataset = MyDataset(train_encodings, train_labels_encoded)\n",
    "    test_dataset = MyDataset(test_encodings, test_labels_encoded)\n",
    "    \n",
    "    training_args = TrainingArguments( #sono sempre gli stessi alla fine\n",
    "    num_train_epochs=4,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=16,   # batch size for evaluation\n",
    "    learning_rate=2e-5,              # initial learning rate for Adam optimizer\n",
    "    warmup_steps=100,                # number of warmup steps for learning rate scheduler (set lower because of small dataset size)\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    output_dir='./results',          # output directory\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=2500,               # number of steps to output logging (set lower because of small dataset size)\n",
    "    evaluation_strategy='steps',     # evaluate during fine-tuning so that we can see progress\n",
    ")\n",
    "    \n",
    "    trainer = Trainer(model=modello, args=training_args)  #basta avere il modello come parametro\n",
    "\n",
    "    predicted_results=trainer.predict(test_dataset)\n",
    " \n",
    "    predicted_labels = predicted_results.predictions.argmax(-1) # Get the highest probability prediction\n",
    " \n",
    "    predicted_labels = predicted_labels.flatten().tolist()      # Flatten the predictions into a 1D list\n",
    "   \n",
    "    predicted_labels = [id2label[l] for l in predicted_labels]  # Convert from integers back to strings for readability\n",
    "        \n",
    "    \n",
    "    \n",
    "    return print(classification_report(test_labels,predicted_labels)),print(confusion_matrix(test_labels,predicted_labels,labels=lista_labels))#aggiunta dopo\n",
    "    #return predicted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fa1440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f7d220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06efd756",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1b3e98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "83501b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/vocab.txt from cache at C:\\Users\\Fossati/.cache\\huggingface\\transformers\\28e5b750bf4f39cc620367720e105de1501cf36ec4ca7029eba82c1d2cc47caf.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n",
      "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/tokenizer.json from cache at C:\\Users\\Fossati/.cache\\huggingface\\transformers\\5cbdf121f196be5f1016cb102b197b0c34009e1e658f513515f2eebef9f38093.b33e51591f94f17c238ee9b1fac75b96ff2678cbaed6e108feadb3449d18dc24\n",
      "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at C:\\Users\\Fossati/.cache\\huggingface\\transformers\\47087d99feeb3bc6184d7576ff089c52f7fbe3219fe48c6c4fa681e617753256.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/config.json from cache at C:\\Users\\Fossati/.cache\\huggingface\\transformers\\cf37a9dc282a679f121734d06f003625d14cfdaf55c14358c4c0b8e7e2b89ac9.7a727bd85e40715bec919a39cdd6f0aba27a8cd488f2d4e0f512448dcd02bf0f\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-multilingual-cased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/config.json from cache at C:\\Users\\Fossati/.cache\\huggingface\\transformers\\cf37a9dc282a679f121734d06f003625d14cfdaf55c14358c4c0b8e7e2b89ac9.7a727bd85e40715bec919a39cdd6f0aba27a8cd488f2d4e0f512448dcd02bf0f\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at C:\\Users\\Fossati/.cache\\huggingface\\transformers\\7b48683e2e7ba71cd1d7d6551ac325eceee01db5c2f3e81cfbfd1ee7bb7877f2.c24097b0cf91dbc66977325325fd03112f0f13d0e3579abbffc8d1e45f8d0619\n",
      "Some weights of the model checkpoint at distilbert-base-multilingual-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "using `logging_steps` to initialize `eval_steps` to 2500\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1298\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='82' max='82' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [82/82 02:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fossati\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Fossati\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Fossati\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Anger       0.43      1.00      0.60       558\n",
      "         Joy       0.00      0.00      0.00       358\n",
      "     Sadness       0.00      0.00      0.00       382\n",
      "\n",
      "    accuracy                           0.43      1298\n",
      "   macro avg       0.14      0.33      0.20      1298\n",
      "weighted avg       0.18      0.43      0.26      1298\n",
      "\n",
      "[[  0   0 382]\n",
      " [  0   0 358]\n",
      " [  0   0 558]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/config.json from cache at C:\\Users\\Fossati/.cache\\huggingface\\transformers\\cf37a9dc282a679f121734d06f003625d14cfdaf55c14358c4c0b8e7e2b89ac9.7a727bd85e40715bec919a39cdd6f0aba27a8cd488f2d4e0f512448dcd02bf0f\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at C:\\Users\\Fossati/.cache\\huggingface\\transformers\\7b48683e2e7ba71cd1d7d6551ac325eceee01db5c2f3e81cfbfd1ee7bb7877f2.c24097b0cf91dbc66977325325fd03112f0f13d0e3579abbffc8d1e45f8d0619\n",
      "Some weights of the model checkpoint at distilbert-base-multilingual-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "using `logging_steps` to initialize `eval_steps` to 2500\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 6838\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='428' max='428' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [428/428 12:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fossati\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Fossati\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Fossati\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Anger       0.00      0.00      0.00      1195\n",
      "        Fear       0.18      0.09      0.12      1184\n",
      "         Joy       0.29      0.92      0.44      1977\n",
      "     Neutral       0.00      0.00      0.00       612\n",
      "     Sadness       0.00      0.00      0.00      1509\n",
      "    Surprise       0.00      0.00      0.00       361\n",
      "\n",
      "    accuracy                           0.28      6838\n",
      "   macro avg       0.08      0.17      0.09      6838\n",
      "weighted avg       0.11      0.28      0.15      6838\n",
      "\n",
      "[[   0    0 1377    0    0  132]\n",
      " [   0    0  340    0    0   21]\n",
      " [   0    0 1818    0    0  159]\n",
      " [   0    0  550    0    0   62]\n",
      " [   0    0 1092    0    0  103]\n",
      " [   0    0 1082    0    0  102]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#baseline mbert su benchmark\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tok = DistilBertTokenizerFast.from_pretrained('distilbert-base-multilingual-cased')\n",
    "\n",
    "\n",
    "\n",
    "#prediction_test(sem_eval_test, modello, tok, ul, l2id, id2l, epoche)\n",
    "modello = DistilBertForSequenceClassification.from_pretrained('distilbert-base-multilingual-cased', num_labels=3)\n",
    "\n",
    "\n",
    "prediction_test_baseline(tweeteval, modello, tok, 2)\n",
    "print('\\n')\n",
    "print('\\n')\n",
    "print('\\n')\n",
    "\n",
    "modello = DistilBertForSequenceClassification.from_pretrained('distilbert-base-multilingual-cased', num_labels=6)\n",
    "prediction_test_baseline(sem_eval_test, modello, tok, 1)\n",
    "\n",
    "\n",
    "#la baseline è peggiore di tutti i modelli mbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405298bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693a9540",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c221bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdeaf06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9e662c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/xlm-roberta-base/resolve/main/sentencepiece.bpe.model from cache at C:\\Users\\Fossati/.cache\\huggingface\\transformers\\9df9ae4442348b73950203b63d1b8ed2d18eba68921872aee0c3a9d05b9673c6.00628a9eeb8baf4080d44a0abe9fe8057893de20c7cb6e6423cddbf452f7d4d8\n",
      "loading file https://huggingface.co/xlm-roberta-base/resolve/main/tokenizer.json from cache at C:\\Users\\Fossati/.cache\\huggingface\\transformers\\daeda8d936162ca65fe6dd158ecce1d8cb56c17d89b78ab86be1558eaef1d76a.a984cf52fc87644bd4a2165f1e07e0ac880272c1e82d648b4674907056912bd7\n",
      "loading file https://huggingface.co/xlm-roberta-base/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/xlm-roberta-base/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/xlm-roberta-base/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/xlm-roberta-base/resolve/main/config.json from cache at C:\\Users\\Fossati/.cache\\huggingface\\transformers\\87683eb92ea383b0475fecf99970e950a03c9ff5e51648d6eee56fb754612465.dfaaaedc7c1c475302398f09706cbb21e23951b73c6e2b3162c1c8a99bb3b62a\n",
      "Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"xlm-roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/xlm-roberta-base/resolve/main/config.json from cache at C:\\Users\\Fossati/.cache\\huggingface\\transformers\\87683eb92ea383b0475fecf99970e950a03c9ff5e51648d6eee56fb754612465.dfaaaedc7c1c475302398f09706cbb21e23951b73c6e2b3162c1c8a99bb3b62a\n",
      "Model config XLMRobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/xlm-roberta-base/resolve/main/pytorch_model.bin from cache at C:\\Users\\Fossati/.cache\\huggingface\\transformers\\97d0ea09f8074264957d062ec20ccb79af7b917d091add8261b26874daf51b5d.f42212747c1c27fcebaa0a89e2a83c38c6d3d4340f21922f892b88d882146ac2\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "using `logging_steps` to initialize `eval_steps` to 2500\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1298\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='82' max='82' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [82/82 04:18]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fossati\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Fossati\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Fossati\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Anger       0.43      1.00      0.60       558\n",
      "         Joy       0.00      0.00      0.00       358\n",
      "     Sadness       0.00      0.00      0.00       382\n",
      "\n",
      "    accuracy                           0.43      1298\n",
      "   macro avg       0.14      0.33      0.20      1298\n",
      "weighted avg       0.18      0.43      0.26      1298\n",
      "\n",
      "[[  0   0 382]\n",
      " [  0   0 358]\n",
      " [  0   0 558]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/xlm-roberta-base/resolve/main/config.json from cache at C:\\Users\\Fossati/.cache\\huggingface\\transformers\\87683eb92ea383b0475fecf99970e950a03c9ff5e51648d6eee56fb754612465.dfaaaedc7c1c475302398f09706cbb21e23951b73c6e2b3162c1c8a99bb3b62a\n",
      "Model config XLMRobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/xlm-roberta-base/resolve/main/pytorch_model.bin from cache at C:\\Users\\Fossati/.cache\\huggingface\\transformers\\97d0ea09f8074264957d062ec20ccb79af7b917d091add8261b26874daf51b5d.f42212747c1c27fcebaa0a89e2a83c38c6d3d4340f21922f892b88d882146ac2\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "using `logging_steps` to initialize `eval_steps` to 2500\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 6838\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='428' max='428' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [428/428 20:41]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Anger       0.14      0.05      0.07      1195\n",
      "        Fear       0.00      0.00      0.00      1184\n",
      "         Joy       0.00      0.00      0.00      1977\n",
      "     Neutral       0.09      0.92      0.16       612\n",
      "     Sadness       0.00      0.00      0.00      1509\n",
      "    Surprise       0.00      0.00      0.00       361\n",
      "\n",
      "    accuracy                           0.09      6838\n",
      "   macro avg       0.04      0.16      0.04      6838\n",
      "weighted avg       0.03      0.09      0.03      6838\n",
      "\n",
      "[[   0    0    0 1414   95    0]\n",
      " [   0    0    0  344   17    0]\n",
      " [   0    0    0 1862  115    0]\n",
      " [   0    0    0  565   47    0]\n",
      " [   0    0    0 1139   56    0]\n",
      " [   0    0    0 1100   84    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fossati\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Fossati\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Fossati\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#baseline XLMR su benchmark\n",
    "\n",
    "\n",
    "tok = XLMRobertaTokenizerFast.from_pretrained('xlm-roberta-base')\n",
    "\n",
    "\n",
    "\n",
    "#prediction_test(sem_eval_test, modello, tok, ul, l2id, id2l, epoche)\n",
    "modello = XLMRobertaForSequenceClassification.from_pretrained('xlm-roberta-base', num_labels=3)\n",
    "\n",
    "\n",
    "prediction_test_baseline(tweeteval, modello, tok, 2)\n",
    "print('\\n')\n",
    "print('\\n')\n",
    "print('\\n')\n",
    "\n",
    "modello = XLMRobertaForSequenceClassification.from_pretrained('xlm-roberta-base', num_labels=6)\n",
    "prediction_test_baseline(sem_eval_test, modello, tok, 1)\n",
    "\n",
    "\n",
    "#la baseline è peggiore di tutti i modelli mbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f562eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbe2fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3db0911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba4ea8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b26eb0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9187ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae6df45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94f4a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f331b9c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "20265cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file Emotions_fin_mbert\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-multilingual-cased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file Emotions_fin_mbert\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at Emotions_fin_mbert.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/vocab.txt from cache at C:\\Users\\Fossati/.cache\\huggingface\\transformers\\28e5b750bf4f39cc620367720e105de1501cf36ec4ca7029eba82c1d2cc47caf.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n",
      "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/tokenizer.json from cache at C:\\Users\\Fossati/.cache\\huggingface\\transformers\\5cbdf121f196be5f1016cb102b197b0c34009e1e658f513515f2eebef9f38093.b33e51591f94f17c238ee9b1fac75b96ff2678cbaed6e108feadb3449d18dc24\n",
      "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at C:\\Users\\Fossati/.cache\\huggingface\\transformers\\47087d99feeb3bc6184d7576ff089c52f7fbe3219fe48c6c4fa681e617753256.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/config.json from cache at C:\\Users\\Fossati/.cache\\huggingface\\transformers\\cf37a9dc282a679f121734d06f003625d14cfdaf55c14358c4c0b8e7e2b89ac9.7a727bd85e40715bec919a39cdd6f0aba27a8cd488f2d4e0f512448dcd02bf0f\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-multilingual-cased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "using `logging_steps` to initialize `eval_steps` to 1500\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 6838\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='428' max='428' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [428/428 04:30]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using `logging_steps` to initialize `eval_steps` to 1500\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1298\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Anger       0.48      0.43      0.45      1195\n",
      "        Fear       0.73      0.44      0.55      1184\n",
      "         Joy       0.70      0.52      0.60      1977\n",
      "     Neutral       0.17      0.55      0.26       612\n",
      "     Sadness       0.68      0.35      0.47      1509\n",
      "    Surprise       0.17      0.40      0.24       361\n",
      "\n",
      "    accuracy                           0.45      6838\n",
      "   macro avg       0.49      0.45      0.43      6838\n",
      "weighted avg       0.59      0.45      0.49      6838\n",
      "\n",
      "[[ 532  187  123  326  273   68]\n",
      " [  14  145   81   78   27   16]\n",
      " [  64  121 1023  642  100   27]\n",
      " [  36   89   68  338   54   27]\n",
      " [  52  155   75  343  517   53]\n",
      " [  79  149   84  231  115  526]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='82' max='82' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [82/82 00:44]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fossati\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Fossati\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Fossati\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "using `logging_steps` to initialize `eval_steps` to 1500\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1298\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Anger       0.85      0.44      0.58       558\n",
      "        Fear       0.00      0.00      0.00         0\n",
      "         Joy       0.77      0.56      0.65       358\n",
      "     Neutral       0.00      0.00      0.00         0\n",
      "     Sadness       0.81      0.46      0.59       382\n",
      "    Surprise       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.48      1298\n",
      "   macro avg       0.40      0.24      0.30      1298\n",
      "weighted avg       0.82      0.48      0.60      1298\n",
      "\n",
      "[[175  41  39  62  21  44]\n",
      " [  0   0   0   0   0   0]\n",
      " [ 13  40 201  65  23  16]\n",
      " [  0   0   0   0   0   0]\n",
      " [ 28  77  20 136 243  54]\n",
      " [  0   0   0   0   0   0]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='82' max='82' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [82/82 00:44]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Anger       0.77      0.75      0.76       558\n",
      "         Joy       0.63      0.79      0.70       358\n",
      "     Sadness       0.75      0.60      0.67       382\n",
      "\n",
      "    accuracy                           0.72      1298\n",
      "   macro avg       0.72      0.71      0.71      1298\n",
      "weighted avg       0.73      0.72      0.72      1298\n",
      "\n",
      "[[228  81  73]\n",
      " [ 20 283  55]\n",
      " [ 54  85 419]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mBERTstrategia finale\n",
    "\n",
    "\n",
    "\n",
    "modello = DistilBertForSequenceClassification.from_pretrained('Emotions_fin_mbert')\n",
    "tok = DistilBertTokenizerFast.from_pretrained('distilbert-base-multilingual-cased')\n",
    "\n",
    "\n",
    "\n",
    "prediction_test(sem_eval_test, modello, tok) \n",
    "print('\\n')\n",
    "print('\\n')\n",
    "print('\\n')\n",
    "prediction_test(tweeteval, modello, tok) \n",
    "print('\\n')\n",
    "print('\\n')\n",
    "print('\\n')\n",
    "prediction_test_whelp(tweeteval, modello, tok)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8542f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#con aiuto mBERT raggiunge un buon 72% do accuracy sulle 3 classi da predire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b53a17a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9993a996",
   "metadata": {},
   "outputs": [],
   "source": [
    "#['Sadness' ,'Joy', 'Anger']\n",
    "#questo è l'ordine delle classi per leggere la confusion matrix 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f69a862",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista_labels=['Sadness', 'Surprise', 'Joy', 'Neutral', 'Anger','Fear']\n",
    "#questo è l'ordine per leggere la confusion matrix 6x6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8d5fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5e6820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42b5735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2373bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b011f97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ab92c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b770bf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file Emotions_fin_xlmr\\config.json\n",
      "Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"xlm-roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "loading weights file Emotions_fin_xlmr\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing XLMRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of XLMRobertaForSequenceClassification were initialized from the model checkpoint at Emotions_fin_xlmr.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use XLMRobertaForSequenceClassification for predictions without further training.\n",
      "loading file https://huggingface.co/xlm-roberta-base/resolve/main/sentencepiece.bpe.model from cache at C:\\Users\\Fossati/.cache\\huggingface\\transformers\\9df9ae4442348b73950203b63d1b8ed2d18eba68921872aee0c3a9d05b9673c6.00628a9eeb8baf4080d44a0abe9fe8057893de20c7cb6e6423cddbf452f7d4d8\n",
      "loading file https://huggingface.co/xlm-roberta-base/resolve/main/tokenizer.json from cache at C:\\Users\\Fossati/.cache\\huggingface\\transformers\\daeda8d936162ca65fe6dd158ecce1d8cb56c17d89b78ab86be1558eaef1d76a.a984cf52fc87644bd4a2165f1e07e0ac880272c1e82d648b4674907056912bd7\n",
      "loading file https://huggingface.co/xlm-roberta-base/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/xlm-roberta-base/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/xlm-roberta-base/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/xlm-roberta-base/resolve/main/config.json from cache at C:\\Users\\Fossati/.cache\\huggingface\\transformers\\87683eb92ea383b0475fecf99970e950a03c9ff5e51648d6eee56fb754612465.dfaaaedc7c1c475302398f09706cbb21e23951b73c6e2b3162c1c8a99bb3b62a\n",
      "Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"xlm-roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "using `logging_steps` to initialize `eval_steps` to 1500\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 6838\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='428' max='428' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [428/428 12:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using `logging_steps` to initialize `eval_steps` to 1500\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1298\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Anger       0.51      0.44      0.47      1195\n",
      "        Fear       0.72      0.43      0.54      1184\n",
      "         Joy       0.72      0.62      0.66      1977\n",
      "     Neutral       0.19      0.54      0.28       612\n",
      "     Sadness       0.68      0.41      0.51      1509\n",
      "    Surprise       0.17      0.33      0.23       361\n",
      "\n",
      "    accuracy                           0.49      6838\n",
      "   macro avg       0.50      0.46      0.45      6838\n",
      "weighted avg       0.60      0.49      0.52      6838\n",
      "\n",
      "[[ 622  150  118  304  256   59]\n",
      " [  20  119  100   73   25   24]\n",
      " [  56   94 1223  504   74   26]\n",
      " [  35   72   90  333   54   28]\n",
      " [  54  142   78  335  527   59]\n",
      " [ 134  111  100  235   89  515]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='82' max='82' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [82/82 01:43]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fossati\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Fossati\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Fossati\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "using `logging_steps` to initialize `eval_steps` to 1500\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1298\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Anger       0.88      0.41      0.56       558\n",
      "        Fear       0.00      0.00      0.00         0\n",
      "         Joy       0.82      0.57      0.67       358\n",
      "     Neutral       0.00      0.00      0.00         0\n",
      "     Sadness       0.83      0.53      0.65       382\n",
      "    Surprise       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.49      1298\n",
      "   macro avg       0.42      0.25      0.31      1298\n",
      "weighted avg       0.85      0.49      0.61      1298\n",
      "\n",
      "[[202  37  20  58  22  43]\n",
      " [  0   0   0   0   0   0]\n",
      " [  8  36 203  79  10  22]\n",
      " [  0   0   0   0   0   0]\n",
      " [ 33  79  24 140 227  55]\n",
      " [  0   0   0   0   0   0]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='82' max='82' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [82/82 01:41]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Anger       0.83      0.72      0.77       558\n",
      "         Joy       0.69      0.86      0.77       358\n",
      "     Sadness       0.77      0.74      0.75       382\n",
      "\n",
      "    accuracy                           0.77      1298\n",
      "   macro avg       0.76      0.77      0.76      1298\n",
      "weighted avg       0.78      0.77      0.77      1298\n",
      "\n",
      "[[281  49  52]\n",
      " [ 20 309  29]\n",
      " [ 63  91 404]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#modello fin XLM-R\n",
    "\n",
    "modello = XLMRobertaForSequenceClassification.from_pretrained('Emotions_fin_xlmr')\n",
    "tok = XLMRobertaTokenizerFast.from_pretrained('xlm-roberta-base')\n",
    "\n",
    "\n",
    "prediction_test(sem_eval_test, modello, tok) \n",
    "print('\\n')\n",
    "print('\\n')\n",
    "print('\\n')\n",
    "prediction_test(tweeteval, modello, tok) \n",
    "print('\\n')\n",
    "print('\\n')\n",
    "print('\\n')\n",
    "prediction_test_whelp(tweeteval, modello, tok)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7645c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#l'ordine con cui leggere le confusion è riportato sopra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd6bcee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffd4c71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733091c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#senza aiuto xlm-r è migliore di mBERT per accuracy\n",
    "#anche con aiuto performa meglio di mBERT XLMR, anche se meno evidentemente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee72ed54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#quindi il modello che sembra essere più adatto ai nostri scopi è XLM-R, in quanto generalmente migliore di mBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23772a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a61355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58aa9fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6375d5af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4f4bed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2216d7c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7df5845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311e4e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2362425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1282a339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ababe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
